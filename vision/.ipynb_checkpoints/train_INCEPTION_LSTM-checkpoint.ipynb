{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN + LSTM Fall Detection on Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/MED_Fall\n"
     ]
    }
   ],
   "source": [
    "%cd '/home/jovyan/work/MED_Fall'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "# Evaluating CNN+RNN models on the dataset\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import random\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import wandb\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import utils\n",
    "from vision.utils.cnn_rnn_utils import load_and_split\n",
    "from vision.utils.dataset import TimeSeriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
    "tf.random.set_seed(hash(\"by removing stochasticity\") % 2**32 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "\n",
    "opt = dotdict(\n",
    "    {\n",
    "        \"lstm1_units\": 128,\n",
    "        \"lstm2_units\": 64,\n",
    "        \"dense_units\": 32,\n",
    "        \"dropout\": 0.5,\n",
    "        \"epochs\": 1000,\n",
    "        \"train_actors\": [1],\n",
    "        \"val_actors\": [2],\n",
    "        \"train_cams\": [1],\n",
    "        \"val_cams\": [1],\n",
    "        \"seq_len\": 20,\n",
    "        \"split_ratio\": None,\n",
    "        \"drop_offair\": False,\n",
    "        \"undersample\": False,\n",
    "        \"batch_size\": 40,\n",
    "        \"stride\": 10,\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"micro_classes\": False,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load InceptionV2 pre-trained features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] Load Train Set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading features: vision_dataset/cnn_features/Actor_1_Walk_Stick_Full_PH.npz: 100%|██████████| 16/16 [00:18<00:00,  1.14s/it]\n",
      "Loading csv datasets: 100%|██████████| 16/16 [00:00<00:00, 33.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] Load Val Set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading features: vision_dataset/cnn_features/Actor_2_Walk_Stick_Full_PH.npz: 100%|██████████| 19/19 [00:18<00:00,  1.05it/s]\n",
      "Loading csv datasets: 100%|██████████| 19/19 [00:00<00:00, 58.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train shape: (60480, 2048), len y_train: 60480, X_val shape: (57120, 2048), len y_val: 57120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, cams_train, cams_val = load_and_split(\n",
    "    features_folder='vision_dataset/cnn_features', dataset_folder='vision_dataset/ground_truth',\n",
    "    train_actors=opt.train_actors, val_actors=opt.val_actors, train_cams=opt.train_cams, val_cams=opt.val_cams,\n",
    "    split_ratio=opt.split_ratio, drop_offair=opt.drop_offair, undersample=opt.undersample,\n",
    "    micro_classes=opt.micro_classes\n",
    "    )\n",
    "print(\n",
    "    f\"\\nX_train shape: {X_train.shape}, len y_train: {len(y_train)}, X_val shape: {X_val.shape}, len y_val: {len(y_val)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4536/4536 [00:00<00:00, 151700.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes mapping:\n",
      "{'adl': 1, 'falling': 2, 'lying_down': 3}\n",
      "\n",
      "Class weights for train series:\n",
      "[0.47772512 4.99009901 1.41573034]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4284/4284 [00:00<00:00, 172658.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train_series shape: (4536, 20, 2048), len y_train_series: 4536, X_val_series shape: (4284, 20, 2048), len y_val_series: 4284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "series_gen = TimeSeriesGenerator(opt)\n",
    "X_train_series, y_train_series, class_weights, classes = series_gen.get_train_series(X_train, y_train, cams_train)\n",
    "X_val_series, y_val_series = series_gen.get_val_series(X_val, y_val, cams_val)\n",
    "print(\n",
    "    f\"\\nX_train_series shape: {X_train_series.shape}, len y_train_series: {len(y_train_series)}, X_val_series shape: {X_val_series.shape}, len y_val_series: {len(y_val_series)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before resampling - y_train_series shape: Counter({0: 3165, 2: 1068, 1: 303})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before resampling - y_train_series shape: {Counter(y_train_series)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample dataset for balancing classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "undersampling_strategy = {0: 3000, 2: 3000, 1: 3000}\n",
    "oversampling_strategy = {0: 23890, 2: 6437, 1: 4000}\n",
    "under = RandomUnderSampler(random_state=2, sampling_strategy=undersampling_strategy)\n",
    "over = RandomOverSampler(random_state=2, sampling_strategy=oversampling_strategy)\n",
    "steps = [(\"o\", over), (\"u\", under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# smt = SMOTETomek(random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X_train_series shape: (4536, 20, 2048)\n",
      "X_train_series reshaped: (4536, 40960)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrea/miniforge3/envs/ml/lib/python3.9/site-packages/imblearn/utils/_validation.py:299: UserWarning: After over-sampling, the number of samples (23890) in class 0 will be larger than the number of samples in the majority class (class #0 -> 3165)\n",
      "  warnings.warn(\n",
      "/Users/andrea/miniforge3/envs/ml/lib/python3.9/site-packages/imblearn/utils/_validation.py:299: UserWarning: After over-sampling, the number of samples (6437) in class 2 will be larger than the number of samples in the majority class (class #0 -> 3165)\n",
      "  warnings.warn(\n",
      "/Users/andrea/miniforge3/envs/ml/lib/python3.9/site-packages/imblearn/utils/_validation.py:299: UserWarning: After over-sampling, the number of samples (4000) in class 1 will be larger than the number of samples in the majority class (class #0 -> 3165)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After resampling X_train_series shape: (9000, 20, 2048)\n",
      "After resampling - y_train_series count: Counter({0: 3000, 1: 3000, 2: 3000})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original X_train_series shape: {X_train_series.shape}\")\n",
    "\n",
    "X_train_series = np.reshape(X_train_series, (-1, 20 * 2048))\n",
    "print(f\"X_train_series reshaped: {X_train_series.shape}\")\n",
    "\n",
    "X_train_series, y_train_series = pipeline.fit_resample(X_train_series, y_train_series)\n",
    "\n",
    "X_train_series = np.reshape(X_train_series, (-1, 20, 2048))\n",
    "\n",
    "print(f\"After resampling X_train_series shape: {X_train_series.shape}\")\n",
    "print(f\"After resampling - y_train_series count: {Counter(y_train_series)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init WANDB project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandreaapi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/andrea/Documents/Github/MED_Fall/vision/wandb/run-20220723_151203-2pn801q1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/andreaapi/Fall%20detection%20CNN%20%2B%20RNN/runs/2pn801q1\" target=\"_blank\">resilient-eon-127</a></strong> to <a href=\"https://wandb.ai/andreaapi/Fall%20detection%20CNN%20%2B%20RNN\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# WANDB project initialization\n",
    "run = wandb.init(\n",
    "    project=\"Fall detection CNN + RNN\",\n",
    "    config={\n",
    "        \"model\": \"LSTM\",\n",
    "        \"epochs\": opt.epochs,\n",
    "        \"seq_len\": opt.seq_len,\n",
    "        \"num_features\": 2048,\n",
    "        \"batch_size\": opt.batch_size,\n",
    "        \"stride\": opt.stride,\n",
    "        \"loss_function\": \"sparse_categorical_crossentropy\",\n",
    "        \"architecture\": \"LSTM\",\n",
    "        \"train_actors\": opt.train_actors,\n",
    "        \"val_actors\": opt.val_actors,\n",
    "        \"train_cams\": opt.train_cams,\n",
    "        \"val_cams\": opt.val_cams,\n",
    "        \"micro_classes\": opt.classes,\n",
    "        \"dropout\": opt.dropout,\n",
    "        \"lstm1_units\": opt.lstm1_units,\n",
    "        \"lstm2_units\": opt.lstm2_units,\n",
    "        \"dense_units\": opt.dense_units,\n",
    "        \"learning_rate\": opt.learning_rate,\n",
    "        \"split_ratio\": opt.split_ratio,\n",
    "        \"drop_offair\": opt.drop_offair,\n",
    "        \"undersample\": opt.undersample,\n",
    "    },\n",
    ")\n",
    "\n",
    "cfg = wandb.config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 15:12:09.840650: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-23 15:12:09.841395: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 20, 128)           1114624   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, 128)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,166,211\n",
      "Trainable params: 1,166,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=cfg.lstm1_units, input_shape=(cfg.seq_len, cfg.num_features), return_sequences=True))\n",
    "model.add(Dropout(cfg.dropout))\n",
    "model.add(LSTM(units=cfg.lstm2_units, input_shape=(cfg.seq_len, cfg.num_features), return_sequences=False))\n",
    "model.add(Dropout(cfg.dropout))\n",
    "model.add(Dense(units=cfg.dense_units, activation=\"relu\"))\n",
    "model.add(Dropout(cfg.dropout))\n",
    "model.add(Dense(units=np.unique(y_train_series, axis=0).shape[0], activation=\"softmax\"))\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=cfg.learning_rate),\n",
    "    loss=cfg.loss_function,\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    }
   ],
   "source": [
    "dir_path = f\"{projectdir}/model_checkpoints/LSTM\"\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "     filepath=f\"{dir_path}/InceptionV2_LSTM_best_epoch.h5\",\n",
    "     monitor=\"val_loss\",\n",
    "     mode=\"min\",\n",
    "     save_best_only=True,\n",
    "     save_weights_only=False,\n",
    "     initial_value_threshold=0.8,\n",
    "     verbose=1,\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.1,\n",
    "    patience=30,\n",
    "    verbose=1,\n",
    "    mode=\"min\",\n",
    "    min_delta=1e-5,\n",
    "    cooldown=1,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "callbacks = [WandbCallback(), reduce_lr, early_stop, model_checkpoint]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 15:12:40.289353: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-07-23 15:12:41.400991: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-23 15:12:41.676561: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-23 15:12:41.852144: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-23 15:12:42.103168: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/225 [..............................] - ETA: 6s - loss: 1.0935 - accuracy: 0.3833  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 15:12:42.471589: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - ETA: 0s - loss: 0.9078 - accuracy: 0.5307"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 15:12:55.550190: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-23 15:12:55.688620: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-23 15:12:55.762489: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 17s 67ms/step - loss: 0.9078 - accuracy: 0.5307 - val_loss: 0.9801 - val_accuracy: 0.1552 - _timestamp: 1658581977.0000 - _runtime: 54.0000 - lr: 1.0000e-04\n",
      "Epoch 2/1000\n",
      "225/225 [==============================] - 9s 40ms/step - loss: 0.7570 - accuracy: 0.5946 - val_loss: 0.9150 - val_accuracy: 0.3525 - _timestamp: 1658581986.0000 - _runtime: 63.0000 - lr: 1.0000e-04\n",
      "Epoch 3/1000\n",
      "225/225 [==============================] - 8s 34ms/step - loss: 0.6633 - accuracy: 0.6997 - val_loss: 1.0949 - val_accuracy: 0.3812 - _timestamp: 1658581994.0000 - _runtime: 71.0000 - lr: 1.0000e-04\n",
      "Epoch 4/1000\n",
      "225/225 [==============================] - 8s 34ms/step - loss: 0.5097 - accuracy: 0.8151 - val_loss: 0.8675 - val_accuracy: 0.5451 - _timestamp: 1658582001.0000 - _runtime: 78.0000 - lr: 1.0000e-04\n",
      "Epoch 5/1000\n",
      "225/225 [==============================] - 7s 30ms/step - loss: 0.4495 - accuracy: 0.8328 - val_loss: 1.2141 - val_accuracy: 0.3324 - _timestamp: 1658582008.0000 - _runtime: 85.0000 - lr: 1.0000e-04\n",
      "Epoch 6/1000\n",
      "225/225 [==============================] - 6s 29ms/step - loss: 0.4162 - accuracy: 0.8480 - val_loss: 1.0927 - val_accuracy: 0.4461 - _timestamp: 1658582015.0000 - _runtime: 92.0000 - lr: 1.0000e-04\n",
      "Epoch 7/1000\n",
      "225/225 [==============================] - 7s 30ms/step - loss: 0.4063 - accuracy: 0.8507 - val_loss: 0.8330 - val_accuracy: 0.6559 - _timestamp: 1658582021.0000 - _runtime: 98.0000 - lr: 1.0000e-04\n",
      "Epoch 8/1000\n",
      "225/225 [==============================] - 7s 29ms/step - loss: 0.3895 - accuracy: 0.8579 - val_loss: 0.8739 - val_accuracy: 0.6440 - _timestamp: 1658582028.0000 - _runtime: 105.0000 - lr: 1.0000e-04\n",
      "Epoch 9/1000\n",
      "225/225 [==============================] - 7s 30ms/step - loss: 0.3580 - accuracy: 0.8760 - val_loss: 0.9091 - val_accuracy: 0.6982 - _timestamp: 1658582035.0000 - _runtime: 112.0000 - lr: 1.0000e-04\n",
      "Epoch 10/1000\n",
      "225/225 [==============================] - 7s 31ms/step - loss: 0.3459 - accuracy: 0.8782 - val_loss: 0.9819 - val_accuracy: 0.6090 - _timestamp: 1658582042.0000 - _runtime: 119.0000 - lr: 1.0000e-04\n",
      "Epoch 11/1000\n",
      "225/225 [==============================] - 100s 446ms/step - loss: 0.3276 - accuracy: 0.8869 - val_loss: 0.9595 - val_accuracy: 0.6776 - _timestamp: 1658582142.0000 - _runtime: 219.0000 - lr: 1.0000e-04\n",
      "Epoch 12/1000\n",
      " 63/225 [=======>......................] - ETA: 15s - loss: 0.3308 - accuracy: 0.8833"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "history = model.fit(X_train_series, y_train_series, validation_data=(X_val_series, y_val_series), epochs=cfg.epochs,\n",
    "                    callbacks=callbacks, batch_size=cfg.batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-20 17:56:58.117224: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-20 17:56:59.093105: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/72 [..............................] - ETA: 3s  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-20 17:57:01.730702: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 6s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_logits = model.predict(X_val_series, batch_size=60, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free up memory\n",
    "# del X_train_series\n",
    "# del y_train_series\n",
    "# del X_val_series\n",
    "# del y_val_series\n",
    "\n",
    "# gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log metrics to wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb.plots.* functions are deprecated and will be removed in a future release. Please use wandb.plot.* instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b6354d3b5c40b0b383ee3ccc93b3e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='13.565 MB of 13.565 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9999…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄▆▆▆▇▇▇▇▇▇▇▇██▇█████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▆▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▄▁▅▄▆▆▇█▇█▇▆▇██▆▇▇▅█▆▆▆▄▄</td></tr><tr><td>val_loss</td><td>▃▃▂▂▁▂▂▂▂▂▂▃▃▄▄▃▆▅▅▄▇▆▆█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Classification Report</td><td>              precis...</td></tr><tr><td>accuracy</td><td>0.92911</td></tr><tr><td>best_epoch</td><td>4</td></tr><tr><td>best_val_loss</td><td>0.77372</td></tr><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.19935</td></tr><tr><td>val_accuracy</td><td>0.62815</td></tr><tr><td>val_loss</td><td>1.30525</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">easy-snow-124</strong>: <a href=\"https://wandb.ai/andreaapi/Fall%20detection%20CNN%20%2B%20RNN/runs/2u6it5m7\" target=\"_blank\">https://wandb.ai/andreaapi/Fall%20detection%20CNN%20%2B%20RNN/runs/2u6it5m7</a><br/>Synced 6 W&B file(s), 5 media file(s), 4 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220720_175222-2u6it5m7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_val_classes = np.argmax(val_logits, axis=1).tolist()\n",
    "\n",
    "cr = classification_report(y_val_series, y_pred_val_classes, target_names=classes)\n",
    "\n",
    "wandb.log({\"Classification Report\": cr})\n",
    "\n",
    "wandb.sklearn.plot_roc(y_val_series, val_logits, classes)\n",
    "wandb.sklearn.plot_class_proportions(y_train_series, y_val_series, classes)\n",
    "wandb.sklearn.plot_precision_recall(y_val_series, val_logits, classes)\n",
    "wandb.sklearn.plot_confusion_matrix(y_val_series, y_pred_val_classes, classes)\n",
    "wandb.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         adl       0.85      0.71      0.77      3244\n",
      "     falling       0.09      0.23      0.13       327\n",
      "  lying_down       0.44      0.45      0.45       713\n",
      "\n",
      "    accuracy                           0.63      4284\n",
      "   macro avg       0.46      0.46      0.45      4284\n",
      "weighted avg       0.72      0.63      0.67      4284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "045da2998f02dde6c755b0fa2e74d8766d7d056d6163358ab445ad432d6df67f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
