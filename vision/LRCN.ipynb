{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cc03ab9-4832-4382-bf60-29d006b6dbad",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7b4f8f2-ff9b-4bb1-bfd1-44ba404783b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ebfb3fe-f9d6-4748-b584-77ebf2c4f43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randrange\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from utils.utility_functions import listdir_nohidden_sorted as lsdir\n",
    "from vision.vision_utils.video_seq_generator_new import VideoSeqGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ab99b99-bbaa-4089-a7bc-0bb0509e8ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe48352f-cfc1-4781-bd8a-116b25beb52c",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c182f2b9-653d-461b-b3a4-359388edbbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MED_FALL = \"/home/jovyan/work/MED_Fall\"\n",
    "GROUND_TRUTH_PATH = f\"{MED_FALL}/vision/vision_dataset/ground_truth_new\"\n",
    "FRAMES_PATH = f\"{MED_FALL}/vision/vision_dataset/extracted_frames\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6053081c-e2bf-4788-96b3-09eeb802c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN: int = 16\n",
    "STRIDE: int = 8\n",
    "BATCH_SIZE: int = 16\n",
    "INPUT_SHAPE: tuple[int, int, int] = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7103cc27-bd03-4583-95f2-1067078394b3",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ac1b25-b220-4847-87c3-7355c5f6c332",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfef0bd3-8400-400d-8e1d-df3a262cd93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cam(name: str) -> int:\n",
    "    \"\"\"\n",
    "    Extract cam number from each video frame name\n",
    "    ------\n",
    "\n",
    "    arguments:\n",
    "        - name: string containing the frame name. Examle: 'Actor_1_bed_cam_1_0000'\n",
    "\n",
    "    outputs:\n",
    "        - cam_number: integer containg the cam number of the provided frame name.\n",
    "                    Example: if name is 'Actor_1_bed_cam_1_0000', cam_number is: 1.\n",
    "    \"\"\"\n",
    "\n",
    "    start = name.find(\"cam_\")\n",
    "    ind = start + 4\n",
    "    cam_number = name[ind]\n",
    "    return int(cam_number)\n",
    "\n",
    "\n",
    "def show_frames_series(\n",
    "    frames_series: np.array, title: str, figsize: tuple[int, int] = (20, 20), nrows=5\n",
    "):\n",
    "    \"\"\"\n",
    "    plot a series of SEQ_LEN frames with respective labels as titles.\n",
    "    --------\n",
    "\n",
    "    arguments:\n",
    "        - frames_series: np.array containg SEQ_LEN images.\n",
    "        - title: strcontainging the label of the series of frame. The label is calculated as the mode (most frequent label) of the single frames' labels.\n",
    "        - fig_size: Optional. Tuple of two integers containing the figure dimensions for the plot. Default is (20, 20).\n",
    "\n",
    "    \"\"\"\n",
    "    rows = nrows\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    for n, image in enumerate(frames_series):\n",
    "        a = fig.add_subplot(rows, int(len(frames_series) / float(rows)), n + 1)\n",
    "\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "    fig.suptitle(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e426db-8691-41f4-b73c-b5a00b78862a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d6b6094-dc5a-42d6-a534-c35d6c77a9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182295</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182296</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182297</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182298</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182299</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1182300 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                micro_labels macro_labels            ar_labels  \\\n",
       "0                  lie_still   lying_down  actor_repositioning   \n",
       "1                  lie_still   lying_down  actor_repositioning   \n",
       "2                  lie_still   lying_down  actor_repositioning   \n",
       "3                  lie_still   lying_down  actor_repositioning   \n",
       "4                  lie_still   lying_down  actor_repositioning   \n",
       "...                      ...          ...                  ...   \n",
       "1182295  stand_up_from_floor          adl  actor_repositioning   \n",
       "1182296  stand_up_from_floor          adl  actor_repositioning   \n",
       "1182297  stand_up_from_floor          adl  actor_repositioning   \n",
       "1182298  stand_up_from_floor          adl  actor_repositioning   \n",
       "1182299  stand_up_from_floor          adl  actor_repositioning   \n",
       "\n",
       "                               frame_name  \n",
       "0                  actor_1_bed_cam_1_0000  \n",
       "1                  actor_1_bed_cam_1_0001  \n",
       "2                  actor_1_bed_cam_1_0002  \n",
       "3                  actor_1_bed_cam_1_0003  \n",
       "4                  actor_1_bed_cam_1_0004  \n",
       "...                                   ...  \n",
       "1182295  actor_4_chair_full_ph_cam_7_4615  \n",
       "1182296  actor_4_chair_full_ph_cam_7_4616  \n",
       "1182297  actor_4_chair_full_ph_cam_7_4617  \n",
       "1182298  actor_4_chair_full_ph_cam_7_4618  \n",
       "1182299  actor_4_chair_full_ph_cam_7_4619  \n",
       "\n",
       "[1182300 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all csv files (one per actor). Each file contains frames names and respective labels.\n",
    "dfs = []\n",
    "for file in lsdir(GROUND_TRUTH_PATH):\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "# concatenate all csv files in one pandas DF\n",
    "dataset = pd.concat(dfs, ignore_index=True, axis=0)\n",
    "dataset = dataset.iloc[:, 2:]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ea79a72-7500-410a-9f02-5c1bd0105670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182213</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182214</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182215</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182216</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182217</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>386106 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              micro_labels macro_labels ar_labels  \\\n",
       "206      sit_up_from_lying          adl    on_air   \n",
       "207      sit_up_from_lying          adl    on_air   \n",
       "208      sit_up_from_lying          adl    on_air   \n",
       "209      sit_up_from_lying          adl    on_air   \n",
       "210      sit_up_from_lying          adl    on_air   \n",
       "...                    ...          ...       ...   \n",
       "1182213     crouched_still      falling    on_air   \n",
       "1182214     crouched_still      falling    on_air   \n",
       "1182215     crouched_still      falling    on_air   \n",
       "1182216     crouched_still      falling    on_air   \n",
       "1182217     crouched_still      falling    on_air   \n",
       "\n",
       "                               frame_name  \n",
       "206                actor_1_bed_cam_1_0206  \n",
       "207                actor_1_bed_cam_1_0207  \n",
       "208                actor_1_bed_cam_1_0208  \n",
       "209                actor_1_bed_cam_1_0209  \n",
       "210                actor_1_bed_cam_1_0210  \n",
       "...                                   ...  \n",
       "1182213  actor_4_chair_full_ph_cam_7_4533  \n",
       "1182214  actor_4_chair_full_ph_cam_7_4534  \n",
       "1182215  actor_4_chair_full_ph_cam_7_4535  \n",
       "1182216  actor_4_chair_full_ph_cam_7_4536  \n",
       "1182217  actor_4_chair_full_ph_cam_7_4537  \n",
       "\n",
       "[386106 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only \"on_air\" frames (where actors are performing sequences)\n",
    "dataset_onair = dataset.loc[dataset[\"ar_labels\"] == \"on_air\"].copy()\n",
    "dataset_onair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b77e37f-05c3-471b-9999-e7dddf7987d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adl           269836\n",
       "falling        88312\n",
       "lying_down     27958\n",
       "Name: macro_labels, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check on_air dataset samples per class\n",
    "dataset_onair[\"macro_labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b55f678b-74c3-471e-b2f5-98c73581d0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adl': array([1, 0, 0]),\n",
       " 'falling': array([0, 1, 0]),\n",
       " 'lying_down': array([0, 0, 1])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate and fit a OneHotEncoder for the macro classes (adl, fall, lie_down)\n",
    "le = LabelBinarizer()\n",
    "le.fit(dataset_onair[\"macro_labels\"])\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "le_name_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92e55d9-cf87-41de-9b43-bfb906e6bfe5",
   "metadata": {},
   "source": [
    "## Use actor 4 as val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fa761da-c221-4e51-b34d-cbaaa1e6bdfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1014006</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_0126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014007</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_0127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014008</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_0128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014009</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_0129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014010</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_0130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182213</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182214</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182215</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182216</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182217</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39368 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              micro_labels macro_labels ar_labels  \\\n",
       "1014006  sit_up_from_lying          adl    on_air   \n",
       "1014007  sit_up_from_lying          adl    on_air   \n",
       "1014008  sit_up_from_lying          adl    on_air   \n",
       "1014009  sit_up_from_lying          adl    on_air   \n",
       "1014010  sit_up_from_lying          adl    on_air   \n",
       "...                    ...          ...       ...   \n",
       "1182213     crouched_still      falling    on_air   \n",
       "1182214     crouched_still      falling    on_air   \n",
       "1182215     crouched_still      falling    on_air   \n",
       "1182216     crouched_still      falling    on_air   \n",
       "1182217     crouched_still      falling    on_air   \n",
       "\n",
       "                               frame_name  \n",
       "1014006            actor_4_bed_cam_1_0126  \n",
       "1014007            actor_4_bed_cam_1_0127  \n",
       "1014008            actor_4_bed_cam_1_0128  \n",
       "1014009            actor_4_bed_cam_1_0129  \n",
       "1014010            actor_4_bed_cam_1_0130  \n",
       "...                                   ...  \n",
       "1182213  actor_4_chair_full_ph_cam_7_4533  \n",
       "1182214  actor_4_chair_full_ph_cam_7_4534  \n",
       "1182215  actor_4_chair_full_ph_cam_7_4535  \n",
       "1182216  actor_4_chair_full_ph_cam_7_4536  \n",
       "1182217  actor_4_chair_full_ph_cam_7_4537  \n",
       "\n",
       "[39368 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_4 = dataset_onair.loc[dataset_onair[\"frame_name\"].str.contains(\"actor_4\")].copy()\n",
    "actor_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54fb5feb-502f-4bc6-a1f8-0bbb5a604808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013767</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_walk_stick_full_ph_cam_7_5767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013768</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_walk_stick_full_ph_cam_7_5768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013769</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_walk_stick_full_ph_cam_7_5769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013770</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_walk_stick_full_ph_cam_7_5770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013771</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_walk_stick_full_ph_cam_7_5771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>346738 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  micro_labels macro_labels ar_labels  \\\n",
       "206          sit_up_from_lying          adl    on_air   \n",
       "207          sit_up_from_lying          adl    on_air   \n",
       "208          sit_up_from_lying          adl    on_air   \n",
       "209          sit_up_from_lying          adl    on_air   \n",
       "210          sit_up_from_lying          adl    on_air   \n",
       "...                        ...          ...       ...   \n",
       "1013767  lie_down_on_the_floor   lying_down    on_air   \n",
       "1013768  lie_down_on_the_floor   lying_down    on_air   \n",
       "1013769  lie_down_on_the_floor   lying_down    on_air   \n",
       "1013770  lie_down_on_the_floor   lying_down    on_air   \n",
       "1013771  lie_down_on_the_floor   lying_down    on_air   \n",
       "\n",
       "                                    frame_name  \n",
       "206                     actor_1_bed_cam_1_0206  \n",
       "207                     actor_1_bed_cam_1_0207  \n",
       "208                     actor_1_bed_cam_1_0208  \n",
       "209                     actor_1_bed_cam_1_0209  \n",
       "210                     actor_1_bed_cam_1_0210  \n",
       "...                                        ...  \n",
       "1013767  actor_3_walk_stick_full_ph_cam_7_5767  \n",
       "1013768  actor_3_walk_stick_full_ph_cam_7_5768  \n",
       "1013769  actor_3_walk_stick_full_ph_cam_7_5769  \n",
       "1013770  actor_3_walk_stick_full_ph_cam_7_5770  \n",
       "1013771  actor_3_walk_stick_full_ph_cam_7_5771  \n",
       "\n",
       "[346738 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = dataset_onair.drop(actor_4.index)\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c08bd3f-d82d-41c3-9a0e-c61504827b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adl           244132\n",
       "falling        75320\n",
       "lying_down     27286\n",
       "Name: macro_labels, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[\"macro_labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1b6a2dc-3cf6-4552-aa66-5f4655da48ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1014006</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_0126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014007</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_0127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014008</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_0128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014009</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_0129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014010</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_0130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182213</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182214</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182215</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182216</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182217</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39368 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              micro_labels macro_labels ar_labels  \\\n",
       "1014006  sit_up_from_lying          adl    on_air   \n",
       "1014007  sit_up_from_lying          adl    on_air   \n",
       "1014008  sit_up_from_lying          adl    on_air   \n",
       "1014009  sit_up_from_lying          adl    on_air   \n",
       "1014010  sit_up_from_lying          adl    on_air   \n",
       "...                    ...          ...       ...   \n",
       "1182213     crouched_still      falling    on_air   \n",
       "1182214     crouched_still      falling    on_air   \n",
       "1182215     crouched_still      falling    on_air   \n",
       "1182216     crouched_still      falling    on_air   \n",
       "1182217     crouched_still      falling    on_air   \n",
       "\n",
       "                               frame_name  \n",
       "1014006            actor_4_bed_cam_1_0126  \n",
       "1014007            actor_4_bed_cam_1_0127  \n",
       "1014008            actor_4_bed_cam_1_0128  \n",
       "1014009            actor_4_bed_cam_1_0129  \n",
       "1014010            actor_4_bed_cam_1_0130  \n",
       "...                                   ...  \n",
       "1182213  actor_4_chair_full_ph_cam_7_4533  \n",
       "1182214  actor_4_chair_full_ph_cam_7_4534  \n",
       "1182215  actor_4_chair_full_ph_cam_7_4535  \n",
       "1182216  actor_4_chair_full_ph_cam_7_4536  \n",
       "1182217  actor_4_chair_full_ph_cam_7_4537  \n",
       "\n",
       "[39368 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set = actor_4\n",
    "val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b254bd96-e99c-4c74-88ab-935673ba7420",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set[\"macro_labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786a45e9-fe4e-4155-9ab1-1b78a6df7f7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Balance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846dd261-b4ad-484b-98f0-be7913e4d343",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_balanced = dataset_onair.copy()  # make a copy of on_air dataset\n",
    "\n",
    "counts = dataset_balanced[\"macro_labels\"].value_counts()  # count samples per class\n",
    "minority_class_samples = counts[-1]  # store minority class samples\n",
    "\n",
    "# select adl samples\n",
    "adl_samples = dataset_onair.loc[dataset[\"macro_labels\"] == \"adl\"]\n",
    "\n",
    "# select fall samples\n",
    "fall_samples = dataset_onair.loc[dataset[\"macro_labels\"] == \"falling\"]\n",
    "\n",
    "## subsample\n",
    "\n",
    "# count exceeding adl samples wrt minority_class_samples\n",
    "adl_todrop_ind = len(adl_samples) - minority_class_samples\n",
    "# count exceeding fall samples wrt minority_class_samples\n",
    "fall_todrop_ind = len(fall_samples) - minority_class_samples\n",
    "\n",
    "# select indices to drop from adl subset\n",
    "adl_samples_to_drop = adl_samples.iloc[-adl_todrop_ind:]\n",
    "\n",
    "# select indices to drop from fall subset\n",
    "fall_samples_to_drop = fall_samples.iloc[-fall_todrop_ind:]\n",
    "\n",
    "# actually drop exceeding adl samples\n",
    "dataset_balanced.drop(adl_samples_to_drop.index, axis=0, inplace=True)\n",
    "\n",
    "# actually drop exceeding fall samples\n",
    "dataset_balanced.drop(fall_samples_to_drop.index, axis=0, inplace=True)\n",
    "\n",
    "# count samples per class of the balanced dataset\n",
    "dataset_balanced[\"macro_labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74de4cd8-3b01-4829-8ed6-565124960b2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae1184e-ef39-46e7-9481-9526e99f1b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take first 90% of the balanced dataset as train data and remaining 10% as val data.\n",
    "# NB: no shuffling is applied as frames must be consecutive to later split them in time-series.\n",
    "split_ratio = 0.9\n",
    "split = int(len(dataset_balanced) * split_ratio)\n",
    "train_set = dataset_balanced.iloc[:split, :].copy()\n",
    "val_set = dataset_balanced.iloc[split:, :].copy()\n",
    "\n",
    "minority_val_samples = val_set[\"macro_labels\"].value_counts()[0]\n",
    "\n",
    "# show samples per class in each set\n",
    "print(train_set[\"macro_labels\"].value_counts())\n",
    "print(val_set[\"macro_labels\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0f2139-a203-43ec-a1fe-2ca0268fe88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show train set\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241e5e8f-6364-46de-bf24-9b00b320ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set_copy = pd.concat(\n",
    "    [\n",
    "        val_set,\n",
    "        adl_samples_to_drop.iloc[0:minority_val_samples, :],\n",
    "        fall_samples_to_drop.iloc[0:minority_val_samples, :],\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "val_set_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e24fc86-f521-4cf2-83b6-d0a074e22047",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set_copy[\"macro_labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc708a4-0528-45e2-9af7-f1e404f7e502",
   "metadata": {},
   "source": [
    "## Instantiate train and val generators\n",
    "### VideoSeqGenerator works as follows:\n",
    "- takes a dataframe containing the frame names and the corresponding labels as input\n",
    "- splits the dataframe in time series of length SEQ_LEN\n",
    "- for each series: \n",
    "    - loads a batch made of BATCH_SIZE * SEQ_LEN frames into a tensor called \"X\"\n",
    "    - for each window (time-series) of the batch caluculates the mode of the frames, applies OneHotEncoding and stores the encoded windows' labels in a tensor called \"y\".\n",
    "    - returns X,y. \n",
    "      X has shape (BATCH_SIZE, SEQ_LEN, IMAGE_SIZE), for example (32, 20, 224, 224, 3)\n",
    "      y has shape (BATCH_SIZE, 3),  where 3 derives from the one hot encoding of the 3 classes (adl, fall, lie_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c6b6042-71b0-4795-9700-48d41bcd0ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "# instantiating train generator. For this test there will be only one generator which takes the whole dataset as input\n",
    "train_gen = VideoSeqGenerator(\n",
    "    frames_path=FRAMES_PATH,\n",
    "    df=train_set,\n",
    "    seq_len=SEQ_LEN,\n",
    "    stride=STRIDE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_encoder=le,\n",
    "    input_shape=INPUT_SHAPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a95c814-914d-4ec3-8bc0-e3dd9d6c6a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "val_gen = VideoSeqGenerator(\n",
    "    frames_path=FRAMES_PATH,\n",
    "    df=val_set,\n",
    "    seq_len=SEQ_LEN,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    stride=STRIDE,\n",
    "    label_encoder=le,\n",
    "    input_shape=INPUT_SHAPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20db45d3-24fe-4db3-a1f1-11a63bfc090b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10824"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen.s_s[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f7c5a57-65ca-4fc3-b2b6-b606b6ca9d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_gen.windows_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bffec70d-31b8-419a-add7-b64595e0d72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adl           119\n",
       "falling        31\n",
       "lying_down      3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(val_gen.windows_labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "476c16b1-46d1-4918-aa84-7feeeaf6467e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1354"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_gen.s_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfc148e3-2830-483e-9361-f18e668a53c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "      <th>cam</th>\n",
       "      <th>actor_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0206</td>\n",
       "      <td>1</td>\n",
       "      <td>1_bed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0207</td>\n",
       "      <td>1</td>\n",
       "      <td>1_bed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0208</td>\n",
       "      <td>1</td>\n",
       "      <td>1_bed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0209</td>\n",
       "      <td>1</td>\n",
       "      <td>1_bed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0210</td>\n",
       "      <td>1</td>\n",
       "      <td>1_bed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013767</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_walk_stick_full_ph_cam_7_5767</td>\n",
       "      <td>7</td>\n",
       "      <td>3_walk_stick_full_ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013768</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_walk_stick_full_ph_cam_7_5768</td>\n",
       "      <td>7</td>\n",
       "      <td>3_walk_stick_full_ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013769</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_walk_stick_full_ph_cam_7_5769</td>\n",
       "      <td>7</td>\n",
       "      <td>3_walk_stick_full_ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013770</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_walk_stick_full_ph_cam_7_5770</td>\n",
       "      <td>7</td>\n",
       "      <td>3_walk_stick_full_ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013771</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_walk_stick_full_ph_cam_7_5771</td>\n",
       "      <td>7</td>\n",
       "      <td>3_walk_stick_full_ph</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>346738 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  micro_labels macro_labels ar_labels  \\\n",
       "206          sit_up_from_lying          adl    on_air   \n",
       "207          sit_up_from_lying          adl    on_air   \n",
       "208          sit_up_from_lying          adl    on_air   \n",
       "209          sit_up_from_lying          adl    on_air   \n",
       "210          sit_up_from_lying          adl    on_air   \n",
       "...                        ...          ...       ...   \n",
       "1013767  lie_down_on_the_floor   lying_down    on_air   \n",
       "1013768  lie_down_on_the_floor   lying_down    on_air   \n",
       "1013769  lie_down_on_the_floor   lying_down    on_air   \n",
       "1013770  lie_down_on_the_floor   lying_down    on_air   \n",
       "1013771  lie_down_on_the_floor   lying_down    on_air   \n",
       "\n",
       "                                    frame_name  cam             actor_seq  \n",
       "206                     actor_1_bed_cam_1_0206    1                 1_bed  \n",
       "207                     actor_1_bed_cam_1_0207    1                 1_bed  \n",
       "208                     actor_1_bed_cam_1_0208    1                 1_bed  \n",
       "209                     actor_1_bed_cam_1_0209    1                 1_bed  \n",
       "210                     actor_1_bed_cam_1_0210    1                 1_bed  \n",
       "...                                        ...  ...                   ...  \n",
       "1013767  actor_3_walk_stick_full_ph_cam_7_5767    7  3_walk_stick_full_ph  \n",
       "1013768  actor_3_walk_stick_full_ph_cam_7_5768    7  3_walk_stick_full_ph  \n",
       "1013769  actor_3_walk_stick_full_ph_cam_7_5769    7  3_walk_stick_full_ph  \n",
       "1013770  actor_3_walk_stick_full_ph_cam_7_5770    7  3_walk_stick_full_ph  \n",
       "1013771  actor_3_walk_stick_full_ph_cam_7_5771    7  3_walk_stick_full_ph  \n",
       "\n",
       "[346738 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56128476-c527-45d3-9cdc-58f84448fe26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "adl           953\n",
       "falling       285\n",
       "lying_down    116\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_gen.windows_labels))\n",
    "pd.Series(train_gen.windows_labels).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a07f2-a987-48ad-b59e-04f1aa2b7ea8",
   "metadata": {},
   "source": [
    "### Plot a frames series from first batch\n",
    "    The first two images are black, in fact they are padding frames, because those two frames in the dataframe were part of another sequence. In other words, such frames had a different camera number with respect to the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e03a6638-9e15-4770-b57d-5569860bea5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_X.shape: (16, 16, 224, 224, 3) batch_y.shape: (16, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get first batch from train generator\n",
    "\n",
    "batch_number = randrange(0, 200)\n",
    "\n",
    "batch_X, batch_y = train_gen.__getitem__(batch_number)\n",
    "print(\"batch_X.shape:\", batch_X.shape, \"batch_y.shape:\", batch_y.shape)\n",
    "\n",
    "window_number = randrange(0, 15)\n",
    "\n",
    "frames = batch_X[window_number]\n",
    "title = np.expand_dims(batch_y[window_number], axis=0)\n",
    "title = le.inverse_transform(title)[0]\n",
    "title\n",
    "\n",
    "show_frames_series(frames, title, figsize=(20, 10), nrows=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb9097b-1722-4141-bc45-3bb049f8cbf9",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6387134d-7f3c-4763-ac13-d6ec0db4458f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-28 17:26:35.306315: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-28 17:26:35.747178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 19094 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# we keep track of the recall (sensitivity, or number of correctly predicted true positive).\n",
    "# This metric is especially important for the fall class, where we want to have maximum recall to be sure we don't miss any fall event.\n",
    "metrics = [\n",
    "    tf.keras.metrics.CategoricalAccuracy(),\n",
    "    tf.keras.metrics.Recall(class_id=0, name=\"adl\"),\n",
    "    tf.keras.metrics.Recall(class_id=1, name=\"fall\"),\n",
    "    tf.keras.metrics.Recall(class_id=2, name=\"lying_down\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4202f22-a08d-456a-8d2a-0ad4022b416d",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a64c3775-b953-4f24-82fd-90d2961bf676",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=f\"{MED_FALL}/vision/models/LRCN.h5\"\n",
    ")\n",
    "\n",
    "callbacks = [model_checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a621150-3a46-4c68-998a-b856cfe8239e",
   "metadata": {},
   "source": [
    "## Define LRCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44279024-0c94-40c7-abcd-a5350dd96b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "convnet = tf.keras.models.load_model(\n",
    "    f\"{MED_FALL}/vision/models/vgg_feature_extractor.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a03618c2-6c81-486d-94d8-a62bbc8ac9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_3 (TimeDist (None, 16, 512)           14714688  \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 16, 256)           787456    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 128)               197120    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 15,699,651\n",
      "Trainable params: 984,963\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LRCN = Sequential()\n",
    "LRCN.add(layers.Input(shape=(SEQ_LEN,) + INPUT_SHAPE))\n",
    "LRCN.add(layers.TimeDistributed(convnet))\n",
    "LRCN.add(layers.LSTM(units=256, return_sequences=True))\n",
    "LRCN.add(layers.LSTM(units=128, return_sequences=False))\n",
    "LRCN.add(layers.Dense(units=3, activation=\"softmax\"))\n",
    "LRCN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824b4946-7a1a-4a5d-b74e-4436b932d09c",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a2997d2-c97a-47a4-9da3-4cb8ec6eb373",
   "metadata": {},
   "outputs": [],
   "source": [
    "LRCN.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0a98c0-590e-4045-80a7-8b35529208ad",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16113ae9-9c1f-4e8c-bf8c-889afcafcf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-28 17:27:39.076714: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-28 17:27:42.526141: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/1354 [..............................] - ETA: 5:44:44 - loss: 1.1987 - categorical_accuracy: 0.0000e+00 - adl: 0.0000e+00 - fall: 0.0000e+00 - lying_down: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-28 17:27:54.272877: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1354/1354 [==============================] - 1038s 756ms/step - loss: 0.8004 - categorical_accuracy: 0.6963 - adl: 0.9981 - fall: 0.0000e+00 - lying_down: 0.0000e+00 - val_loss: 0.7701 - val_categorical_accuracy: 0.6560 - val_adl: 1.0000 - val_fall: 0.0000e+00 - val_lying_down: 0.0000e+00\n",
      "Epoch 2/20\n",
      "   3/1354 [..............................] - ETA: 3:59:49 - loss: 1.2133 - categorical_accuracy: 0.3542 - adl: 1.0000 - fall: 0.0000e+00 - lying_down: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Keras_worker_ForkPoolWorker-4:\n",
      "Process Keras_worker_ForkPoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/utils/data_utils.py\", line 563, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/work/MED_Fall/vision/vision_utils/video_seq_generator.py\", line 220, in __getitem__\n",
      "    X, y = self.get_video_seq(pd.DataFrame(self.df.iloc[start:end, :]))\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/pool.py\", line 131, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/home/jovyan/work/MED_Fall/vision/vision_utils/video_seq_generator.py\", line 195, in get_video_seq\n",
      "    loaded_image = self.__load_image(self.frames_path, name, extension=\"jpg\",\n",
      "  File \"/home/jovyan/work/MED_Fall/vision/vision_utils/video_seq_generator.py\", line 127, in __load_image\n",
      "    image = cv2.imread(f\"{images_dir}/{name}.{extension}\")\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/queues.py\", line 378, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/connection.py\", line 410, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "KeyboardInterrupt\n",
      "Exception in thread Thread-25:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/pool.py\", line 576, in _handle_results\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/connection.py\", line 256, in recv\n",
      "    return _ForkingPickler.loads(buf.getbuffer())\n",
      "_pickle.UnpicklingError: invalid load key, '\\x00'.\n",
      "Process Keras_worker_ForkPoolWorker-7:\n",
      "Process Keras_worker_ForkPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/queues.py\", line 366, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/pool.py\", line 131, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/connection.py\", line 221, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/queues.py\", line 378, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/connection.py\", line 410, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/connection.py\", line 384, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "history = LRCN.fit(train_gen, validation_data=val_gen, epochs=20, shuffle=True, callbacks=callbacks, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e217a7a0-95ce-4cb3-ba91-29652bdc5353",
   "metadata": {},
   "outputs": [],
   "source": [
    "LRCN.save(f\"{MED_FALL}/vision/models/LRCN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d979e9-cd63-46e6-bf31-e2a0f959e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LRCN = tf.keras.models.load_model(f\"{MED_FALL}/vision/models/LRCN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e8f514-3fe9-46a1-9586-d92260fda257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(train_gen, validation_data=val_gen, epochs=50, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b490c53-42d4-4b9a-a221-1cbe81427f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model(f\"{MED_FALL}/vision/models/3DCNN+ConvLSTM2D.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f43a9-d487-4d81-b2e7-e86d1073c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accuracies\n",
    "plt.figure()\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f313de88-e4c1-47fa-ae46-a4da4390dce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the losses\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac773c-a5c8-494e-8a99-2140435d263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_logits = model.predict(val_gen)\n",
    "print(y_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc54b8c-ef23-4722-a3ca-4791035feded",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_encoded = []\n",
    "for logit in y_logits:\n",
    "    one_hot_labl = [0, 0, 0]\n",
    "    argmax = np.argmax(logit, axis=0)\n",
    "    one_hot_labl[argmax] = 1\n",
    "    y_preds_encoded.append(one_hot_labl)\n",
    "\n",
    "y_preds_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa5731a-7598-48ce-b682-1f305ead0ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_gen.windows_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d5923b-3835-4987-9bcb-b464a624b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = val_gen.windows_labels[0:2448]\n",
    "pd.Series(y_true).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9796da69-2ce4-4449-87e2-ce539e31b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_encoded = le.transform(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6d086d-ab57-48c1-9078-ce1a30df8df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        y_true=y_true_encoded,\n",
    "        y_pred=y_preds_encoded,\n",
    "        target_names=[\"adl\", \"fall\", \"lie_down\"],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bbfb8f-b541-415e-8d92-45e7762ee9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030d4d99-f4ab-40c5-a894-05eb2aad5aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b9afeb-5c10-4333-b1ac-e98f2ae2e9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
