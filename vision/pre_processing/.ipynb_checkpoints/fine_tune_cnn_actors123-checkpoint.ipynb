{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectdir = \"/home/jovyan/work/MED_Fall\"\n",
    "workdir = \"/home/jovyan/work\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/work/MED_Fall'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTHONPATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from utils.utility_functions import listdir_nohidden_sorted as lsdir\n",
    "from utils.utility_functions import load_images, show_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup the dataframe for keras flow_from_dataframe pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_frames_path = (\n",
    "    \"/home/jovyan/work/MED_Fall/vision/vision_dataset/extracted_frames/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUND_TRUTH_PATH = \"/home/jovyan/work/MED_Fall/vision/vision_dataset/ground_truth_new\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182295</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182296</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182297</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182298</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182299</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1182300 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                micro_labels macro_labels            ar_labels  \\\n",
       "0                  lie_still   lying_down  actor_repositioning   \n",
       "1                  lie_still   lying_down  actor_repositioning   \n",
       "2                  lie_still   lying_down  actor_repositioning   \n",
       "3                  lie_still   lying_down  actor_repositioning   \n",
       "4                  lie_still   lying_down  actor_repositioning   \n",
       "...                      ...          ...                  ...   \n",
       "1182295  stand_up_from_floor          adl  actor_repositioning   \n",
       "1182296  stand_up_from_floor          adl  actor_repositioning   \n",
       "1182297  stand_up_from_floor          adl  actor_repositioning   \n",
       "1182298  stand_up_from_floor          adl  actor_repositioning   \n",
       "1182299  stand_up_from_floor          adl  actor_repositioning   \n",
       "\n",
       "                               frame_name  \n",
       "0                  actor_1_bed_cam_1_0000  \n",
       "1                  actor_1_bed_cam_1_0001  \n",
       "2                  actor_1_bed_cam_1_0002  \n",
       "3                  actor_1_bed_cam_1_0003  \n",
       "4                  actor_1_bed_cam_1_0004  \n",
       "...                                   ...  \n",
       "1182295  actor_4_chair_full_ph_cam_7_4615  \n",
       "1182296  actor_4_chair_full_ph_cam_7_4616  \n",
       "1182297  actor_4_chair_full_ph_cam_7_4617  \n",
       "1182298  actor_4_chair_full_ph_cam_7_4618  \n",
       "1182299  actor_4_chair_full_ph_cam_7_4619  \n",
       "\n",
       "[1182300 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all csv files (one per actor). Each file contains frames names and respective labels.\n",
    "dfs = []\n",
    "for file in lsdir(GROUND_TRUTH_PATH):\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "# concatenate all csv files in one pandas DF\n",
    "dataset = pd.concat(dfs, ignore_index=True, axis=0)\n",
    "dataset = dataset.iloc[:, 2:]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182213</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182214</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182215</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182216</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182217</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>386106 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              micro_labels macro_labels ar_labels  \\\n",
       "206      sit_up_from_lying          adl    on_air   \n",
       "207      sit_up_from_lying          adl    on_air   \n",
       "208      sit_up_from_lying          adl    on_air   \n",
       "209      sit_up_from_lying          adl    on_air   \n",
       "210      sit_up_from_lying          adl    on_air   \n",
       "...                    ...          ...       ...   \n",
       "1182213     crouched_still      falling    on_air   \n",
       "1182214     crouched_still      falling    on_air   \n",
       "1182215     crouched_still      falling    on_air   \n",
       "1182216     crouched_still      falling    on_air   \n",
       "1182217     crouched_still      falling    on_air   \n",
       "\n",
       "                               frame_name  \n",
       "206                actor_1_bed_cam_1_0206  \n",
       "207                actor_1_bed_cam_1_0207  \n",
       "208                actor_1_bed_cam_1_0208  \n",
       "209                actor_1_bed_cam_1_0209  \n",
       "210                actor_1_bed_cam_1_0210  \n",
       "...                                   ...  \n",
       "1182213  actor_4_chair_full_ph_cam_7_4533  \n",
       "1182214  actor_4_chair_full_ph_cam_7_4534  \n",
       "1182215  actor_4_chair_full_ph_cam_7_4535  \n",
       "1182216  actor_4_chair_full_ph_cam_7_4536  \n",
       "1182217  actor_4_chair_full_ph_cam_7_4537  \n",
       "\n",
       "[386106 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only \"on_air\" frames (where actors are performing sequences)\n",
    "dataset_onair = dataset.loc[dataset[\"ar_labels\"] == \"on_air\"].copy()\n",
    "dataset_onair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adl           269836\n",
       "falling        88312\n",
       "lying_down     27958\n",
       "Name: macro_labels, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check on_air dataset samples per class\n",
    "dataset_onair[\"macro_labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adl': array([1, 0, 0]),\n",
       " 'falling': array([0, 1, 0]),\n",
       " 'lying_down': array([0, 0, 1])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate and fit a OneHotEncoder for the macro classes (adl, fall, lie_down)\n",
    "le = LabelBinarizer()\n",
    "le.fit(dataset_onair[\"macro_labels\"])\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "le_name_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use actor 3 as val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>823349</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_bed_cam_1_0149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823350</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_bed_cam_1_0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823351</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_bed_cam_1_0151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823352</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_bed_cam_1_0152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823353</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_bed_cam_1_0153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182213</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182214</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182215</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182216</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182217</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119077 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              micro_labels macro_labels ar_labels  \\\n",
       "823349   sit_up_from_lying          adl    on_air   \n",
       "823350   sit_up_from_lying          adl    on_air   \n",
       "823351   sit_up_from_lying          adl    on_air   \n",
       "823352   sit_up_from_lying          adl    on_air   \n",
       "823353   sit_up_from_lying          adl    on_air   \n",
       "...                    ...          ...       ...   \n",
       "1182213     crouched_still      falling    on_air   \n",
       "1182214     crouched_still      falling    on_air   \n",
       "1182215     crouched_still      falling    on_air   \n",
       "1182216     crouched_still      falling    on_air   \n",
       "1182217     crouched_still      falling    on_air   \n",
       "\n",
       "                               frame_name  \n",
       "823349             actor_3_bed_cam_1_0149  \n",
       "823350             actor_3_bed_cam_1_0150  \n",
       "823351             actor_3_bed_cam_1_0151  \n",
       "823352             actor_3_bed_cam_1_0152  \n",
       "823353             actor_3_bed_cam_1_0153  \n",
       "...                                   ...  \n",
       "1182213  actor_4_chair_full_ph_cam_7_4533  \n",
       "1182214  actor_4_chair_full_ph_cam_7_4534  \n",
       "1182215  actor_4_chair_full_ph_cam_7_4535  \n",
       "1182216  actor_4_chair_full_ph_cam_7_4536  \n",
       "1182217  actor_4_chair_full_ph_cam_7_4537  \n",
       "\n",
       "[119077 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_3 = dataset_onair.loc[dataset_onair[\"frame_name\"].str.contains(\"actor_3\")].copy()\n",
    "actor_4 = dataset_onair.loc[dataset_onair[\"frame_name\"].str.contains(\"actor_4\")].copy()\n",
    "\n",
    "actor_34 = pd.concat([actor_3, actor_4], axis=0)\n",
    "actor_34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822862</th>\n",
       "      <td>fall_lateral</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_2_walk_stick_full_ph_cam_7_0982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822863</th>\n",
       "      <td>fall_lateral</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_2_walk_stick_full_ph_cam_7_0983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822864</th>\n",
       "      <td>fall_lateral</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_2_walk_stick_full_ph_cam_7_0984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822865</th>\n",
       "      <td>fall_lateral</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_2_walk_stick_full_ph_cam_7_0985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822866</th>\n",
       "      <td>fall_lateral</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_2_walk_stick_full_ph_cam_7_0986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>267029 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             micro_labels macro_labels ar_labels  \\\n",
       "206     sit_up_from_lying          adl    on_air   \n",
       "207     sit_up_from_lying          adl    on_air   \n",
       "208     sit_up_from_lying          adl    on_air   \n",
       "209     sit_up_from_lying          adl    on_air   \n",
       "210     sit_up_from_lying          adl    on_air   \n",
       "...                   ...          ...       ...   \n",
       "822862       fall_lateral      falling    on_air   \n",
       "822863       fall_lateral      falling    on_air   \n",
       "822864       fall_lateral      falling    on_air   \n",
       "822865       fall_lateral      falling    on_air   \n",
       "822866       fall_lateral      falling    on_air   \n",
       "\n",
       "                                   frame_name  \n",
       "206                    actor_1_bed_cam_1_0206  \n",
       "207                    actor_1_bed_cam_1_0207  \n",
       "208                    actor_1_bed_cam_1_0208  \n",
       "209                    actor_1_bed_cam_1_0209  \n",
       "210                    actor_1_bed_cam_1_0210  \n",
       "...                                       ...  \n",
       "822862  actor_2_walk_stick_full_ph_cam_7_0982  \n",
       "822863  actor_2_walk_stick_full_ph_cam_7_0983  \n",
       "822864  actor_2_walk_stick_full_ph_cam_7_0984  \n",
       "822865  actor_2_walk_stick_full_ph_cam_7_0985  \n",
       "822866  actor_2_walk_stick_full_ph_cam_7_0986  \n",
       "\n",
       "[267029 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_12 = dataset_onair.drop(actor_34.index)\n",
    "actor_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = actor_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adl           182630\n",
       "falling        60851\n",
       "lying_down     23548\n",
       "Name: macro_labels, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[\"macro_labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adl           61502\n",
       "falling       14469\n",
       "lying_down     3738\n",
       "Name: macro_labels, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set = actor_3\n",
    "val_set[\"macro_labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Balance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adl           23548\n",
       "falling       23548\n",
       "lying_down    23548\n",
       "Name: macro_labels, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset_balanced = dataset_onair.copy()  # make a copy of on_air dataset\n",
    "\n",
    "counts = train_set[\"macro_labels\"].value_counts()  # count samples per class\n",
    "minority_class_samples = counts[-1]  # store minority class samples\n",
    "\n",
    "# select adl samples\n",
    "adl_samples = train_set.loc[dataset[\"macro_labels\"] == \"adl\"]\n",
    "\n",
    "# select fall samples\n",
    "fall_samples = train_set.loc[dataset[\"macro_labels\"] == \"falling\"]\n",
    "\n",
    "## subsample\n",
    "\n",
    "# count exceeding adl samples wrt minority_class_samples\n",
    "adl_todrop_ind = len(adl_samples) - minority_class_samples\n",
    "# count exceeding fall samples wrt minority_class_samples\n",
    "fall_todrop_ind = len(fall_samples) - minority_class_samples\n",
    "\n",
    "# select indices to drop from adl subset\n",
    "adl_samples_to_drop = adl_samples.iloc[-adl_todrop_ind:]\n",
    "\n",
    "# select indices to drop from fall subset\n",
    "fall_samples_to_drop = fall_samples.iloc[-fall_todrop_ind:]\n",
    "\n",
    "# actually drop exceeding adl samples\n",
    "train_set.drop(adl_samples_to_drop.index, axis=0, inplace=True)\n",
    "\n",
    "# actually drop exceeding fall samples\n",
    "train_set.drop(fall_samples_to_drop.index, axis=0, inplace=True)\n",
    "\n",
    "# count samples per class of the balanced dataset\n",
    "train_set[\"macro_labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneHotEncode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "      <th>onehotlabels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0206</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0207</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0208</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0209</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0210</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810180</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_2_walk_ph_cam_7_1260</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810181</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_2_walk_ph_cam_7_1261</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810182</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_2_walk_ph_cam_7_1262</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810183</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_2_walk_ph_cam_7_1263</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810184</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_2_walk_ph_cam_7_1264</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70644 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 micro_labels macro_labels ar_labels  \\\n",
       "206         sit_up_from_lying          adl    on_air   \n",
       "207         sit_up_from_lying          adl    on_air   \n",
       "208         sit_up_from_lying          adl    on_air   \n",
       "209         sit_up_from_lying          adl    on_air   \n",
       "210         sit_up_from_lying          adl    on_air   \n",
       "...                       ...          ...       ...   \n",
       "810180  lie_down_on_the_floor   lying_down    on_air   \n",
       "810181  lie_down_on_the_floor   lying_down    on_air   \n",
       "810182  lie_down_on_the_floor   lying_down    on_air   \n",
       "810183  lie_down_on_the_floor   lying_down    on_air   \n",
       "810184  lie_down_on_the_floor   lying_down    on_air   \n",
       "\n",
       "                        frame_name onehotlabels  \n",
       "206         actor_1_bed_cam_1_0206    [1, 0, 0]  \n",
       "207         actor_1_bed_cam_1_0207    [1, 0, 0]  \n",
       "208         actor_1_bed_cam_1_0208    [1, 0, 0]  \n",
       "209         actor_1_bed_cam_1_0209    [1, 0, 0]  \n",
       "210         actor_1_bed_cam_1_0210    [1, 0, 0]  \n",
       "...                            ...          ...  \n",
       "810180  actor_2_walk_ph_cam_7_1260    [0, 0, 1]  \n",
       "810181  actor_2_walk_ph_cam_7_1261    [0, 0, 1]  \n",
       "810182  actor_2_walk_ph_cam_7_1262    [0, 0, 1]  \n",
       "810183  actor_2_walk_ph_cam_7_1263    [0, 0, 1]  \n",
       "810184  actor_2_walk_ph_cam_7_1264    [0, 0, 1]  \n",
       "\n",
       "[70644 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehotlabels = list(le.transform(train_set[\"macro_labels\"]))\n",
    "train_set[\"onehotlabels\"] = onehotlabels\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "      <th>onehotlabels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>823349</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_bed_cam_1_0149</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823350</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_bed_cam_1_0150</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823351</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_bed_cam_1_0151</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823352</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_bed_cam_1_0152</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823353</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_bed_cam_1_0153</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013767</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_walk_stick_full_ph_cam_7_5767</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013768</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_walk_stick_full_ph_cam_7_5768</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013769</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_walk_stick_full_ph_cam_7_5769</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013770</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_walk_stick_full_ph_cam_7_5770</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013771</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_walk_stick_full_ph_cam_7_5771</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79709 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  micro_labels macro_labels ar_labels  \\\n",
       "823349       sit_up_from_lying          adl    on_air   \n",
       "823350       sit_up_from_lying          adl    on_air   \n",
       "823351       sit_up_from_lying          adl    on_air   \n",
       "823352       sit_up_from_lying          adl    on_air   \n",
       "823353       sit_up_from_lying          adl    on_air   \n",
       "...                        ...          ...       ...   \n",
       "1013767  lie_down_on_the_floor   lying_down    on_air   \n",
       "1013768  lie_down_on_the_floor   lying_down    on_air   \n",
       "1013769  lie_down_on_the_floor   lying_down    on_air   \n",
       "1013770  lie_down_on_the_floor   lying_down    on_air   \n",
       "1013771  lie_down_on_the_floor   lying_down    on_air   \n",
       "\n",
       "                                    frame_name onehotlabels  \n",
       "823349                  actor_3_bed_cam_1_0149    [1, 0, 0]  \n",
       "823350                  actor_3_bed_cam_1_0150    [1, 0, 0]  \n",
       "823351                  actor_3_bed_cam_1_0151    [1, 0, 0]  \n",
       "823352                  actor_3_bed_cam_1_0152    [1, 0, 0]  \n",
       "823353                  actor_3_bed_cam_1_0153    [1, 0, 0]  \n",
       "...                                        ...          ...  \n",
       "1013767  actor_3_walk_stick_full_ph_cam_7_5767    [0, 0, 1]  \n",
       "1013768  actor_3_walk_stick_full_ph_cam_7_5768    [0, 0, 1]  \n",
       "1013769  actor_3_walk_stick_full_ph_cam_7_5769    [0, 0, 1]  \n",
       "1013770  actor_3_walk_stick_full_ph_cam_7_5770    [0, 0, 1]  \n",
       "1013771  actor_3_walk_stick_full_ph_cam_7_5771    [0, 0, 1]  \n",
       "\n",
       "[79709 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_onehotlabels = list(le.transform(val_set[\"macro_labels\"]))\n",
    "val_set[\"onehotlabels\"] = val_onehotlabels\n",
    "val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[\"frame_name\"] += \".jpg\"\n",
    "val_set[\"frame_name\"] += \".jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fine tunframe_nameG16 on Actor 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Training and Validation Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70644 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# istantiate train ImageDataGenerator and define image augmentations.\n",
    "train_generator = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "# flow from dataframe loads frames from provided df, which is Actor 4 subset after balancing.\n",
    "train_datagen = train_generator.flow_from_dataframe(\n",
    "    train_set,\n",
    "    directory=extracted_frames_path,\n",
    "    x_col=\"frame_name\",\n",
    "    y_col=\"macro_labels\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    classes=[\"adl\", \"lying_down\", \"falling\"],\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    seed=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79709 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# define validation ImageDataGenerator. No data augmentation is performed. The images are just rescaled to (0,1)\n",
    "val_generator = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "val_datagen = val_generator.flow_from_dataframe(\n",
    "    val_set,\n",
    "    directory=extracted_frames_path,\n",
    "    x_col=\"frame_name\",\n",
    "    y_col=\"macro_labels\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    classes=[\"adl\", \"lying_down\", \"falling\"],\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    seed=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    23548\n",
      "1    23548\n",
      "2    23548\n",
      "dtype: int64\n",
      "{'adl': 0, 'falling': 1, 'lying_down': 2}\n"
     ]
    }
   ],
   "source": [
    "# print samples per class identified from train generator\n",
    "print(pd.Series(train_datagen.classes).value_counts())\n",
    "print(train_datagen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    61502\n",
      "1    14469\n",
      "2     3738\n",
      "dtype: int64\n",
      "{'adl': 0, 'falling': 1, 'lying_down': 2}\n"
     ]
    }
   ],
   "source": [
    "# print samples per class identified from val generator\n",
    "print(pd.Series(val_datagen.classes).value_counts())\n",
    "print(val_datagen.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download pre-trained VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define image size \n",
    "IMG_SIZE = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-12 21:51:13.270946: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-12 21:51:13.733624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22030 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 5s 0us/step\n",
      "58900480/58889256 [==============================] - 5s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Download VGG16 pre-trained on ImageNet\n",
    "feature_extractor = tf.keras.applications.vgg16.VGG16(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=IMG_SIZE,\n",
    "    pooling=\"avg\",\n",
    ")\n",
    "\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze all layers except last convolutional block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv2 False\n",
      "3 block1_pool False\n",
      "4 block2_conv1 False\n",
      "5 block2_conv2 False\n",
      "6 block2_pool False\n",
      "7 block3_conv1 False\n",
      "8 block3_conv2 False\n",
      "9 block3_conv3 False\n",
      "10 block3_pool False\n",
      "11 block4_conv1 True\n",
      "12 block4_conv2 True\n",
      "13 block4_conv3 True\n",
      "14 block4_pool True\n",
      "15 block5_conv1 True\n",
      "16 block5_conv2 True\n",
      "17 block5_conv3 True\n",
      "18 block5_pool True\n",
      "19 global_average_pooling2d True\n"
     ]
    }
   ],
   "source": [
    "# freeze all layers except last five\n",
    "for layer in feature_extractor.layers[:-9]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for i, layer in enumerate(feature_extractor.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add top layer to fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 15,109,443\n",
      "Trainable params: 13,373,955\n",
      "Non-trainable params: 1,735,488\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# adding two dense layers (512 and 256 units). Final dense layer with 3 neurons.\n",
    "x = feature_extractor.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(units=512, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(units=256, activation=\"relu\")(x)\n",
    "x = Dense(units=3, activation=\"softmax\")(x)\n",
    "\n",
    "transfer_model = Model(inputs=feature_extractor.input, outputs=x)\n",
    "\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model and define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# compile the model and keep track of each class's recall\n",
    "transfer_model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\n",
    "        \"categorical_accuracy\",\n",
    "        tf.keras.metrics.Recall(class_id=0),\n",
    "        tf.keras.metrics.Recall(class_id=1),\n",
    "        tf.keras.metrics.Recall(class_id=2),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint the model every epoch if val_loss improves\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    f\"{projectdir}/vision/models/VGG_finetune_actor_123.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode=\"min\",\n",
    "    save_freq=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    model_checkpoint,\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        verbose=1\n",
    "    ),  # reduces optimizer's lr if val_loss stops decreasing\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        patience=5, verbose=1\n",
    "    ),  # early stops the training if val_loss increases for 5 epochs straight\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-12 21:51:20.441739: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-12 21:51:22.269494: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n",
      "2022-09-12 21:51:25.904815: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1104/1104 [==============================] - 697s 625ms/step - loss: 1.1543 - categorical_accuracy: 0.3322 - recall: 0.0013 - recall_1: 0.0017 - recall_2: 7.6440e-04 - val_loss: 1.1073 - val_categorical_accuracy: 0.1815 - val_recall: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1104/1104 [==============================] - 677s 614ms/step - loss: 1.0987 - categorical_accuracy: 0.3334 - recall: 0.0000e+00 - recall_1: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 1.0923 - val_categorical_accuracy: 0.7716 - val_recall: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1104/1104 [==============================] - 684s 620ms/step - loss: 1.0987 - categorical_accuracy: 0.3302 - recall: 0.0000e+00 - recall_1: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 1.0934 - val_categorical_accuracy: 0.7716 - val_recall: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1104/1104 [==============================] - 679s 615ms/step - loss: 1.0987 - categorical_accuracy: 0.3315 - recall: 0.0000e+00 - recall_1: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 1.0966 - val_categorical_accuracy: 0.7716 - val_recall: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 5/30\n",
      " 264/1104 [======>.......................] - ETA: 6:53 - loss: 1.0986 - categorical_accuracy: 0.3336 - recall: 0.0000e+00 - recall_1: 0.0000e+00 - recall_2: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1104/1104 [==============================] - 680s 616ms/step - loss: 1.0987 - categorical_accuracy: 0.3296 - recall: 0.0000e+00 - recall_1: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 1.0947 - val_categorical_accuracy: 0.7716 - val_recall: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1104/1104 [==============================] - 681s 617ms/step - loss: 1.0987 - categorical_accuracy: 0.3348 - recall: 0.0000e+00 - recall_1: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 1.0955 - val_categorical_accuracy: 0.1815 - val_recall: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1104/1104 [==============================] - 679s 615ms/step - loss: 1.0986 - categorical_accuracy: 0.3347 - recall: 0.0000e+00 - recall_1: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 1.1030 - val_categorical_accuracy: 0.0469 - val_recall: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 19/30\n",
      " 174/1104 [===>..........................] - ETA: 7:33 - loss: 1.0987 - categorical_accuracy: 0.3318 - recall: 0.0000e+00 - recall_1: 0.0000e+00 - recall_2: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1104/1104 [==============================] - 683s 619ms/step - loss: 1.0987 - categorical_accuracy: 0.3345 - recall: 0.0000e+00 - recall_1: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 1.1018 - val_categorical_accuracy: 0.0469 - val_recall: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1104/1104 [==============================] - 677s 613ms/step - loss: 1.0987 - categorical_accuracy: 0.3349 - recall: 0.0000e+00 - recall_1: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 1.1060 - val_categorical_accuracy: 0.1815 - val_recall: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_recall_2: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# fit the model for 100 epochs\n",
    "history = transfer_model.fit(\n",
    "    train_datagen, validation_data=val_datagen, epochs=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprojectdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/vision/models/VGG_finetune_actor_123.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(f\"{projectdir}/vision/models/VGG_finetune_actor_123.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: /home/jovyan/work/MED_Fall/vision/models/VGG_finetune_actor_123.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load best checkpoint\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprojectdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/vision/models/VGG_finetune_actor_123.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/saving/save.py:205\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    203\u001b[0m       filepath \u001b[38;5;241m=\u001b[39m path_to_string(filepath)\n\u001b[1;32m    204\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaved_model_load\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnable to load model. Filepath is not an hdf5 file (or h5py is not \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavailable) or SavedModel.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/saving/saved_model/load.py:108\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, compile, options)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# TODO(kathywu): Add saving/loading of optimizer, compiled losses and metrics.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# TODO(kathywu): Add code to load from objects that contain all endpoints\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Look for metadata file or parse the SavedModel\u001b[39;00m\n\u001b[1;32m    107\u001b[0m metadata \u001b[38;5;241m=\u001b[39m saved_metadata_pb2\u001b[38;5;241m.\u001b[39mSavedMetadata()\n\u001b[0;32m--> 108\u001b[0m meta_graph_def \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmeta_graphs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    109\u001b[0m object_graph_def \u001b[38;5;241m=\u001b[39m meta_graph_def\u001b[38;5;241m.\u001b[39mobject_graph_def\n\u001b[1;32m    110\u001b[0m path_to_metadata_pb \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, constants\u001b[38;5;241m.\u001b[39mSAVED_METADATA_PATH)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/loader_impl.py:118\u001b[0m, in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot parse file \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (path_to_pbtxt, \u001b[38;5;28mstr\u001b[39m(e)))\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[1;32m    119\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModel file does not exist at: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m{\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m|\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    120\u001b[0m       (export_dir, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msep, constants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PBTXT,\n\u001b[1;32m    121\u001b[0m        constants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PB))\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: /home/jovyan/work/MED_Fall/vision/models/VGG_finetune_actor_123.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "# load best checkpoint\n",
    "best_model = tf.keras.models.load_model(\n",
    "    f\"{projectdir}/vision/models/VGG_finetune_actor_123.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on the val set\n",
    "best_model.evaluate(val_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# plot the accuracies\u001b[39;00m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the accuracies\n",
    "plt.figure()\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the losses\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_logits = best_model.predict(val_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = np.argmax(y_preds_logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print classification report\n",
    "print(\n",
    "    classification_report(\n",
    "        y_true=val_datagen.classes,\n",
    "        y_pred=y_preds,\n",
    "        target_names=list(val_datagen.class_indices.keys()),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(train_datagen.classes).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cp ~/work/MED_Fall/vision/model_checkpoints/resample/vgg_top_fine_tuned_best_epoch_undersample.h5 ~/work/persistent/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Features Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detach the previously added dense layers\n",
    "feature_extractor = Sequential(best_model.layers[:-5])\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze again al layers\n",
    "for layer in feature_extractor.layers:\n",
    "    layer.trainable = False\n",
    "for layer in feature_extractor.layers:\n",
    "    print(layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the feature extractor\n",
    "feature_extractor.save(f\"{projectdir}/vision/models/vgg_feature_extractor.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict a fake image to check that output size is the correct number of features.\n",
    "pred_test = feature_extractor.predict(np.ones(shape=(1, 224, 224, 3)))\n",
    "print(pred_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "045da2998f02dde6c755b0fa2e74d8766d7d056d6163358ab445ad432d6df67f"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
