{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectdir = \"/home/jovyan/work/MED_Fall\"\n",
    "workdir = \"/home/jovyan/work\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/work/MED_Fall/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTHONPATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "\n",
    "from vision.pre_processing.extract_frames import FramesExtractor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from utils.utility_functions import listdir_nohidden_sorted as lsdir\n",
    "from utils.utility_functions import load_images, show_images\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup the dataframe for keras flow_from_dataframe pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_frames_path = (\n",
    "    \"/home/jovyan/work/MED_Fall/vision/vision_dataset/extracted_frames\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_old_path = (\n",
    "    \"/home/jovyan/work/MED_Fall/vision/vision_dataset/ground_truth_old\"\n",
    ")\n",
    "ground_truth_path = \"/home/jovyan/work/MED_Fall/vision/vision_dataset/ground_truth\"\n",
    "len(lsdir(ground_truth_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for file in lsdir(ground_truth_path):\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "dataset = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_old = []\n",
    "for file in lsdir(ground_truth_old_path):\n",
    "    df_old = pd.read_csv(file)\n",
    "    dfs_old.append(df_old)\n",
    "dataset_old = pd.concat(dfs_old, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0004.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182295</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4615.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182296</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4616.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182297</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4617.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182298</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4618.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182299</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4619.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1182300 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                micro_labels macro_labels            ar_labels  \\\n",
       "0                  lie_still   lying_down  actor_repositioning   \n",
       "1                  lie_still   lying_down  actor_repositioning   \n",
       "2                  lie_still   lying_down  actor_repositioning   \n",
       "3                  lie_still   lying_down  actor_repositioning   \n",
       "4                  lie_still   lying_down  actor_repositioning   \n",
       "...                      ...          ...                  ...   \n",
       "1182295  stand_up_from_floor          adl  actor_repositioning   \n",
       "1182296  stand_up_from_floor          adl  actor_repositioning   \n",
       "1182297  stand_up_from_floor          adl  actor_repositioning   \n",
       "1182298  stand_up_from_floor          adl  actor_repositioning   \n",
       "1182299  stand_up_from_floor          adl  actor_repositioning   \n",
       "\n",
       "                                   frame_name  \n",
       "0                  actor_1_bed_cam_1_0000.jpg  \n",
       "1                  actor_1_bed_cam_1_0001.jpg  \n",
       "2                  actor_1_bed_cam_1_0002.jpg  \n",
       "3                  actor_1_bed_cam_1_0003.jpg  \n",
       "4                  actor_1_bed_cam_1_0004.jpg  \n",
       "...                                       ...  \n",
       "1182295  actor_4_chair_full_ph_cam_7_4615.jpg  \n",
       "1182296  actor_4_chair_full_ph_cam_7_4616.jpg  \n",
       "1182297  actor_4_chair_full_ph_cam_7_4617.jpg  \n",
       "1182298  actor_4_chair_full_ph_cam_7_4618.jpg  \n",
       "1182299  actor_4_chair_full_ph_cam_7_4619.jpg  \n",
       "\n",
       "[1182300 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"frame_name\"] = (\n",
    "    dataset_old[\"frame_name\"] + \".jpg\"\n",
    ")  # add extension to file_names\n",
    "\n",
    "dataset = dataset.iloc[:, 1:]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualize some frames from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0206.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0207.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0208.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0209.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0210.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182213</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4533.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182214</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4534.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182215</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4535.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182216</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4536.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182217</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4537.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>386106 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              micro_labels macro_labels ar_labels  \\\n",
       "206      sit_up_from_lying          adl    on_air   \n",
       "207      sit_up_from_lying          adl    on_air   \n",
       "208      sit_up_from_lying          adl    on_air   \n",
       "209      sit_up_from_lying          adl    on_air   \n",
       "210      sit_up_from_lying          adl    on_air   \n",
       "...                    ...          ...       ...   \n",
       "1182213     crouched_still      falling    on_air   \n",
       "1182214     crouched_still      falling    on_air   \n",
       "1182215     crouched_still      falling    on_air   \n",
       "1182216     crouched_still      falling    on_air   \n",
       "1182217     crouched_still      falling    on_air   \n",
       "\n",
       "                                   frame_name  \n",
       "206                actor_1_bed_cam_1_0206.jpg  \n",
       "207                actor_1_bed_cam_1_0207.jpg  \n",
       "208                actor_1_bed_cam_1_0208.jpg  \n",
       "209                actor_1_bed_cam_1_0209.jpg  \n",
       "210                actor_1_bed_cam_1_0210.jpg  \n",
       "...                                       ...  \n",
       "1182213  actor_4_chair_full_ph_cam_7_4533.jpg  \n",
       "1182214  actor_4_chair_full_ph_cam_7_4534.jpg  \n",
       "1182215  actor_4_chair_full_ph_cam_7_4535.jpg  \n",
       "1182216  actor_4_chair_full_ph_cam_7_4536.jpg  \n",
       "1182217  actor_4_chair_full_ph_cam_7_4537.jpg  \n",
       "\n",
       "[386106 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##removector actor repositioning frames\n",
    "on_air_ds = dataset.loc[dataset[\"ar_labels\"] == \"on_air\"]\n",
    "on_air_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1051626</th>\n",
       "      <td>rolling_bed</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_2_6666.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335484</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_walk_ph_cam_2_2664.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561800</th>\n",
       "      <td>rolling_bed</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_2_bed_rolling_armour_cam_5_0140.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527754</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_2_bed_ph_cam_3_1494.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663706</th>\n",
       "      <td>walking</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_2_walk_cam_2_1966.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              micro_labels macro_labels ar_labels  \\\n",
       "1051626        rolling_bed          adl    on_air   \n",
       "335484   sit_up_from_lying          adl    on_air   \n",
       "561800         rolling_bed          adl    on_air   \n",
       "527754   sit_up_from_lying          adl    on_air   \n",
       "663706             walking          adl    on_air   \n",
       "\n",
       "                                        frame_name  \n",
       "1051626         actor_4_bed_full_ph_cam_2_6666.jpg  \n",
       "335484              actor_1_walk_ph_cam_2_2664.jpg  \n",
       "561800   actor_2_bed_rolling_armour_cam_5_0140.jpg  \n",
       "527754               actor_2_bed_ph_cam_3_1494.jpg  \n",
       "663706                 actor_2_walk_cam_2_1966.jpg  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_samples = on_air_ds.groupby(\"macro_labels\").sample(n=10)\n",
    "rand_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1051626            actor_4_bed_full_ph_cam_2_6666.jpg -- adl\n",
       "335484                 actor_1_walk_ph_cam_2_2664.jpg -- adl\n",
       "561800      actor_2_bed_rolling_armour_cam_5_0140.jpg -- adl\n",
       "527754                  actor_2_bed_ph_cam_3_1494.jpg -- adl\n",
       "663706                    actor_2_walk_cam_2_1966.jpg -- adl\n",
       "693821                    actor_2_walk_cam_6_4241.jpg -- adl\n",
       "1136327                  actor_4_chair_cam_2_0407.jpg -- adl\n",
       "265422           actor_1_walk2_full_ph_cam_7_6522.jpg -- adl\n",
       "414300      actor_1_walk_stick_full_ph_cam_2_0300.jpg -- adl\n",
       "729864         actor_2_walk_armour_obj_cam_1_2424.jpg -- adl\n",
       "996050     actor_3_walk_stick_full_ph_cam_4_5690.jpg -- f...\n",
       "817547     actor_2_walk_stick_full_ph_cam_3_0947.jpg -- f...\n",
       "838206                 actor_3_bed_cam_6_1806.jpg -- falling\n",
       "480161          actor_2_bed_armour_cam_4_1661.jpg -- falling\n",
       "266399       actor_1_walk2_full_ph_cam_7_7499.jpg -- falling\n",
       "463305                 actor_2_bed_cam_7_1785.jpg -- falling\n",
       "424113                 actor_2_bed_cam_1_0753.jpg -- falling\n",
       "595608        actor_2_chair_armour_cam_3_0648.jpg -- falling\n",
       "250835       actor_1_walk2_full_ph_cam_5_7535.jpg -- falling\n",
       "639639            actor_2_chair_ph_cam_5_2379.jpg -- falling\n",
       "891074     actor_3_chair_full_ph_cam_5_1154.jpg -- lying_...\n",
       "874238            actor_3_chair_cam_5_0578.jpg -- lying_down\n",
       "58769       actor_1_bed_full_ph_cam_6_3929.jpg -- lying_down\n",
       "164787     actor_1_chair_full_ph_cam_3_2367.jpg -- lying_...\n",
       "838257              actor_3_bed_cam_6_1857.jpg -- lying_down\n",
       "400752     actor_1_walk_shoe_full_ph_cam_5_5772.jpg -- ly...\n",
       "73511            actor_1_bed_ph_cam_3_0911.jpg -- lying_down\n",
       "323409     actor_1_walk_full_ph_cam_6_2589.jpg -- lying_down\n",
       "568160     actor_2_bed_rolling_ph_cam_2_0920.jpg -- lying...\n",
       "420657     actor_1_walk_stick_full_ph_cam_6_0417.jpg -- l...\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##concatenare alla macro label il nome del fotogramma\n",
    "titles = rand_samples[\"frame_name\"] + \" -- \" + rand_samples[\"macro_labels\"]\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>439923</th>\n",
       "      <td>lie_down_from_sitting</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_2_bed_cam_3_3843.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 micro_labels macro_labels            ar_labels  \\\n",
       "439923  lie_down_from_sitting          adl  actor_repositioning   \n",
       "\n",
       "                        frame_name  \n",
       "439923  actor_2_bed_cam_3_3843.jpg  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[dataset[\"frame_name\"] == \"actor_2_bed_cam_3_3843.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_images() missing 1 required positional argument: 'resize_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mload_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextracted_frames_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrand_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mframe_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m show_images(\n\u001b[1;32m      4\u001b[0m     images,\n\u001b[1;32m      5\u001b[0m     rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m      6\u001b[0m     figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m20\u001b[39m),\n\u001b[1;32m      7\u001b[0m     titles\u001b[38;5;241m=\u001b[39mtitles,\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: load_images() missing 1 required positional argument: 'resize_shape'"
     ]
    }
   ],
   "source": [
    "images = load_images(extracted_frames_path, rand_samples[\"frame_name\"])\n",
    "\n",
    "show_images(\n",
    "    images,\n",
    "    rows=5,\n",
    "    figsize=(30, 20),\n",
    "    titles=titles,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Subsample dataset choosing Actor 4 as fine tuning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only actor 4\n",
    "actor_4_dataset = dataset[dataset[\"frame_name\"].str.contains(\"actor_4\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_bed_cam_1_0000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_bed_cam_1_0001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_bed_cam_1_0002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_bed_cam_1_0003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_bed_cam_1_0004.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168415</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4615.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168416</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4616.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168417</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4617.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168418</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4618.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168419</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4619.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168420 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               micro_labels macro_labels            ar_labels  \\\n",
       "0                 lie_still   lying_down  actor_repositioning   \n",
       "1                 lie_still   lying_down  actor_repositioning   \n",
       "2                 lie_still   lying_down  actor_repositioning   \n",
       "3                 lie_still   lying_down  actor_repositioning   \n",
       "4                 lie_still   lying_down  actor_repositioning   \n",
       "...                     ...          ...                  ...   \n",
       "168415  stand_up_from_floor          adl  actor_repositioning   \n",
       "168416  stand_up_from_floor          adl  actor_repositioning   \n",
       "168417  stand_up_from_floor          adl  actor_repositioning   \n",
       "168418  stand_up_from_floor          adl  actor_repositioning   \n",
       "168419  stand_up_from_floor          adl  actor_repositioning   \n",
       "\n",
       "                                  frame_name  \n",
       "0                 actor_4_bed_cam_1_0000.jpg  \n",
       "1                 actor_4_bed_cam_1_0001.jpg  \n",
       "2                 actor_4_bed_cam_1_0002.jpg  \n",
       "3                 actor_4_bed_cam_1_0003.jpg  \n",
       "4                 actor_4_bed_cam_1_0004.jpg  \n",
       "...                                      ...  \n",
       "168415  actor_4_chair_full_ph_cam_7_4615.jpg  \n",
       "168416  actor_4_chair_full_ph_cam_7_4616.jpg  \n",
       "168417  actor_4_chair_full_ph_cam_7_4617.jpg  \n",
       "168418  actor_4_chair_full_ph_cam_7_4618.jpg  \n",
       "168419  actor_4_chair_full_ph_cam_7_4619.jpg  \n",
       "\n",
       "[168420 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_4_dataset.reset_index(drop=True, inplace=True)\n",
    "actor_4_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_0126.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_0127.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_0128.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_0129.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_0130.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168333</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4533.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168334</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4534.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168335</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4535.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168336</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4536.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168337</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4537.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39368 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             micro_labels macro_labels ar_labels  \\\n",
       "126     sit_up_from_lying          adl    on_air   \n",
       "127     sit_up_from_lying          adl    on_air   \n",
       "128     sit_up_from_lying          adl    on_air   \n",
       "129     sit_up_from_lying          adl    on_air   \n",
       "130     sit_up_from_lying          adl    on_air   \n",
       "...                   ...          ...       ...   \n",
       "168333     crouched_still      falling    on_air   \n",
       "168334     crouched_still      falling    on_air   \n",
       "168335     crouched_still      falling    on_air   \n",
       "168336     crouched_still      falling    on_air   \n",
       "168337     crouched_still      falling    on_air   \n",
       "\n",
       "                                  frame_name  \n",
       "126               actor_4_bed_cam_1_0126.jpg  \n",
       "127               actor_4_bed_cam_1_0127.jpg  \n",
       "128               actor_4_bed_cam_1_0128.jpg  \n",
       "129               actor_4_bed_cam_1_0129.jpg  \n",
       "130               actor_4_bed_cam_1_0130.jpg  \n",
       "...                                      ...  \n",
       "168333  actor_4_chair_full_ph_cam_7_4533.jpg  \n",
       "168334  actor_4_chair_full_ph_cam_7_4534.jpg  \n",
       "168335  actor_4_chair_full_ph_cam_7_4535.jpg  \n",
       "168336  actor_4_chair_full_ph_cam_7_4536.jpg  \n",
       "168337  actor_4_chair_full_ph_cam_7_4537.jpg  \n",
       "\n",
       "[39368 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_4_dataset = actor_4_dataset.loc[actor_4_dataset[\"ar_labels\"] == \"on_air\"]\n",
    "actor_4_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_images() missing 1 required positional argument: 'resize_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m some_actor_4_samples \u001b[38;5;241m=\u001b[39m actor_4_dataset\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mload_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextracted_frames_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msome_actor_4_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mframe_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m show_images(images, titles\u001b[38;5;241m=\u001b[39msome_actor_4_samples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: load_images() missing 1 required positional argument: 'resize_shape'"
     ]
    }
   ],
   "source": [
    "some_actor_4_samples = actor_4_dataset.groupby(\"macro_labels\").sample(n=5)\n",
    "images = load_images(extracted_frames_path, some_actor_4_samples[\"frame_name\"])\n",
    "\n",
    "show_images(images, titles=some_actor_4_samples[\"macro_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35431, 4) (3937, 4)\n"
     ]
    }
   ],
   "source": [
    "train_set = actor_4_dataset.sample(frac=0.9, random_state=2)\n",
    "val_set = actor_4_dataset.drop(train_set.index)\n",
    "\n",
    "print(train_set.shape, val_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adl           23140\n",
       "falling       11677\n",
       "lying_down      614\n",
       "Name: macro_labels, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[\"macro_labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stand_up_from_sit</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_cam_3_1280.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rolling_bed</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_3_6665.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rolling_bed</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_7_6653.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_7_0827.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_5_2467.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23135</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_7_0718.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23136</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_0594.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23137</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_4_3192.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23138</th>\n",
       "      <td>stand_up_from_sit</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_3_1521.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23139</th>\n",
       "      <td>stand_up_from_sit</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_6_0232.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23140 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            micro_labels macro_labels ar_labels  \\\n",
       "0      stand_up_from_sit          adl    on_air   \n",
       "1            rolling_bed          adl    on_air   \n",
       "2            rolling_bed          adl    on_air   \n",
       "3      sit_up_from_lying          adl    on_air   \n",
       "4      sit_up_from_lying          adl    on_air   \n",
       "...                  ...          ...       ...   \n",
       "23135  sit_up_from_lying          adl    on_air   \n",
       "23136  sit_up_from_lying          adl    on_air   \n",
       "23137  sit_up_from_lying          adl    on_air   \n",
       "23138  stand_up_from_sit          adl    on_air   \n",
       "23139  stand_up_from_sit          adl    on_air   \n",
       "\n",
       "                                 frame_name  \n",
       "0              actor_4_chair_cam_3_1280.jpg  \n",
       "1        actor_4_bed_full_ph_cam_3_6665.jpg  \n",
       "2        actor_4_bed_full_ph_cam_7_6653.jpg  \n",
       "3        actor_4_bed_full_ph_cam_7_0827.jpg  \n",
       "4        actor_4_bed_full_ph_cam_5_2467.jpg  \n",
       "...                                     ...  \n",
       "23135    actor_4_bed_full_ph_cam_7_0718.jpg  \n",
       "23136            actor_4_bed_cam_1_0594.jpg  \n",
       "23137    actor_4_bed_full_ph_cam_4_3192.jpg  \n",
       "23138  actor_4_chair_full_ph_cam_3_1521.jpg  \n",
       "23139            actor_4_bed_cam_6_0232.jpg  \n",
       "\n",
       "[23140 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adl_train = train_set.loc[train_set[\"macro_labels\"] == \"adl\"]\n",
    "adl_train.reset_index(drop=True, inplace=True)\n",
    "adl_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11677"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lying_down_n_samples = train_set[\"macro_labels\"].value_counts()[1]\n",
    "lying_down_n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15847</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_2_3172.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10831</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_1_1795.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21927</th>\n",
       "      <td>stand_up_from_sit</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_cam_4_1319.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>stand_up_from_sit</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_1_4425.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11744</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_5_0807.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9346</th>\n",
       "      <td>stand_up_from_sit</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_cam_7_1280.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>stand_up_from_sit</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_1225.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22070</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_5_2274.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_4_0724.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15293</th>\n",
       "      <td>stand_up_from_sit</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_knee_cam_1_1130.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11677 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            micro_labels macro_labels ar_labels  \\\n",
       "15847  sit_up_from_lying          adl    on_air   \n",
       "10831  sit_up_from_lying          adl    on_air   \n",
       "21927  stand_up_from_sit          adl    on_air   \n",
       "2059   stand_up_from_sit          adl    on_air   \n",
       "11744  sit_up_from_lying          adl    on_air   \n",
       "...                  ...          ...       ...   \n",
       "9346   stand_up_from_sit          adl    on_air   \n",
       "1622   stand_up_from_sit          adl    on_air   \n",
       "22070  sit_up_from_lying          adl    on_air   \n",
       "2725   sit_up_from_lying          adl    on_air   \n",
       "15293  stand_up_from_sit          adl    on_air   \n",
       "\n",
       "                                    frame_name  \n",
       "15847       actor_4_bed_full_ph_cam_2_3172.jpg  \n",
       "10831       actor_4_bed_full_ph_cam_1_1795.jpg  \n",
       "21927             actor_4_chair_cam_4_1319.jpg  \n",
       "2059      actor_4_chair_full_ph_cam_1_4425.jpg  \n",
       "11744       actor_4_bed_full_ph_cam_5_0807.jpg  \n",
       "...                                        ...  \n",
       "9346              actor_4_chair_cam_7_1280.jpg  \n",
       "1622                actor_4_bed_cam_1_1225.jpg  \n",
       "22070               actor_4_bed_cam_5_2274.jpg  \n",
       "2725        actor_4_bed_full_ph_cam_4_0724.jpg  \n",
       "15293  actor_4_bed_full_ph_knee_cam_1_1130.jpg  \n",
       "\n",
       "[11677 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adl_train_under = adl_train.sample(n=lying_down_n_samples, random_state=2)\n",
    "adl_train_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158570</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_5_4010.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72172</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_5_5812.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156754</th>\n",
       "      <td>fall_lateral</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_5_2194.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111137</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_knee_cam_7_1217.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18422</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_7_1862.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146953</th>\n",
       "      <td>fall_lateral</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_3_1633.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17235</th>\n",
       "      <td>fall_frontal</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_7_0675.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142899</th>\n",
       "      <td>fall_lateral</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_2_2199.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17262</th>\n",
       "      <td>fall_frontal</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_7_0702.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146931</th>\n",
       "      <td>fall_lateral</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_3_1611.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12291 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 micro_labels macro_labels ar_labels  \\\n",
       "158570         crouched_still      falling    on_air   \n",
       "72172   lie_down_on_the_floor   lying_down    on_air   \n",
       "156754           fall_lateral      falling    on_air   \n",
       "111137         crouched_still      falling    on_air   \n",
       "18422   lie_down_on_the_floor   lying_down    on_air   \n",
       "...                       ...          ...       ...   \n",
       "146953           fall_lateral      falling    on_air   \n",
       "17235            fall_frontal      falling    on_air   \n",
       "142899           fall_lateral      falling    on_air   \n",
       "17262            fall_frontal      falling    on_air   \n",
       "146931           fall_lateral      falling    on_air   \n",
       "\n",
       "                                     frame_name  \n",
       "158570     actor_4_chair_full_ph_cam_5_4010.jpg  \n",
       "72172        actor_4_bed_full_ph_cam_5_5812.jpg  \n",
       "156754     actor_4_chair_full_ph_cam_5_2194.jpg  \n",
       "111137  actor_4_bed_full_ph_knee_cam_7_1217.jpg  \n",
       "18422                actor_4_bed_cam_7_1862.jpg  \n",
       "...                                         ...  \n",
       "146953     actor_4_chair_full_ph_cam_3_1633.jpg  \n",
       "17235                actor_4_bed_cam_7_0675.jpg  \n",
       "142899     actor_4_chair_full_ph_cam_2_2199.jpg  \n",
       "17262                actor_4_bed_cam_7_0702.jpg  \n",
       "146931     actor_4_chair_full_ph_cam_3_1611.jpg  \n",
       "\n",
       "[12291 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_copy = train_set.copy()\n",
    "train_set_copy = train_set_copy[train_set_copy[\"macro_labels\"] != \"adl\"]\n",
    "train_set_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "falling       11677\n",
       "lying_down      614\n",
       "Name: macro_labels, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_copy[\"macro_labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158570</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_5_4010.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72172</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_5_5812.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156754</th>\n",
       "      <td>fall_lateral</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_5_2194.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111137</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_knee_cam_7_1217.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18422</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_7_1862.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9346</th>\n",
       "      <td>stand_up_from_sit</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_cam_7_1280.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>stand_up_from_sit</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_1225.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22070</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_5_2274.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_4_0724.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15293</th>\n",
       "      <td>stand_up_from_sit</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_knee_cam_1_1130.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23968 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 micro_labels macro_labels ar_labels  \\\n",
       "158570         crouched_still      falling    on_air   \n",
       "72172   lie_down_on_the_floor   lying_down    on_air   \n",
       "156754           fall_lateral      falling    on_air   \n",
       "111137         crouched_still      falling    on_air   \n",
       "18422   lie_down_on_the_floor   lying_down    on_air   \n",
       "...                       ...          ...       ...   \n",
       "9346        stand_up_from_sit          adl    on_air   \n",
       "1622        stand_up_from_sit          adl    on_air   \n",
       "22070       sit_up_from_lying          adl    on_air   \n",
       "2725        sit_up_from_lying          adl    on_air   \n",
       "15293       stand_up_from_sit          adl    on_air   \n",
       "\n",
       "                                     frame_name  \n",
       "158570     actor_4_chair_full_ph_cam_5_4010.jpg  \n",
       "72172        actor_4_bed_full_ph_cam_5_5812.jpg  \n",
       "156754     actor_4_chair_full_ph_cam_5_2194.jpg  \n",
       "111137  actor_4_bed_full_ph_knee_cam_7_1217.jpg  \n",
       "18422                actor_4_bed_cam_7_1862.jpg  \n",
       "...                                         ...  \n",
       "9346               actor_4_chair_cam_7_1280.jpg  \n",
       "1622                 actor_4_bed_cam_1_1225.jpg  \n",
       "22070                actor_4_bed_cam_5_2274.jpg  \n",
       "2725         actor_4_bed_full_ph_cam_4_0724.jpg  \n",
       "15293   actor_4_bed_full_ph_knee_cam_1_1130.jpg  \n",
       "\n",
       "[23968 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_copy = pd.concat([train_set_copy, adl_train_under], axis=0)\n",
    "train_set_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "falling       11677\n",
       "adl           11677\n",
       "lying_down      614\n",
       "Name: macro_labels, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_copy[\"macro_labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_images() missing 1 required positional argument: 'resize_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m some_samples \u001b[38;5;241m=\u001b[39m train_set_copy\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mload_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextracted_frames_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msome_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mframe_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m show_images(images, titles\u001b[38;5;241m=\u001b[39msome_samples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: load_images() missing 1 required positional argument: 'resize_shape'"
     ]
    }
   ],
   "source": [
    "some_samples = train_set_copy.groupby(\"macro_labels\").sample(n=5)\n",
    "images = load_images(extracted_frames_path, some_samples[\"frame_name\"])\n",
    "\n",
    "show_images(images, titles=some_samples[\"macro_labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fine tune VGG16 on Actor 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Training and Validation Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23968 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "\n",
    "train_datagen = train_generator.flow_from_dataframe(\n",
    "    train_set_copy,\n",
    "    directory=extracted_frames_path,\n",
    "    x_col=\"frame_name\",\n",
    "    y_col=\"macro_labels\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    classes=[\"adl\", \"lying_down\", \"falling\"],\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    seed=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3937 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "val_datagen = val_generator.flow_from_dataframe(\n",
    "    val_set,\n",
    "    directory=extracted_frames_path,\n",
    "    x_col=\"frame_name\",\n",
    "    y_col=\"macro_labels\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    classes=[\"adl\", \"lying_down\", \"falling\"],\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    seed=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    11677\n",
      "0    11677\n",
      "2      614\n",
      "dtype: int64\n",
      "{'adl': 0, 'falling': 1, 'lying_down': 2}\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(train_datagen.classes).value_counts())\n",
    "print(train_datagen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2564\n",
      "1    1315\n",
      "2      58\n",
      "dtype: int64\n",
      "{'adl': 0, 'falling': 1, 'lying_down': 2}\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(val_datagen.classes).value_counts())\n",
    "print(val_datagen.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download pre-trained VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m feature_extractor \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapplications\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvgg16\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVGG16\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpooling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mavg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m feature_extractor\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/applications/vgg16.py:141\u001b[0m, in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m    139\u001b[0m     img_input \u001b[38;5;241m=\u001b[39m input_tensor\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# Block 1\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mblock1_conv1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv2D(\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblock1_conv2\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[1;32m    146\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mMaxPooling2D((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m), strides\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblock1_pool\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py:976\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;66;03m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;66;03m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _in_functional_construction_mode(\u001b[38;5;28mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[0;32m--> 976\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_functional_construction_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[1;32m    980\u001b[0m call_context \u001b[38;5;241m=\u001b[39m base_layer_utils\u001b[38;5;241m.\u001b[39mcall_context()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py:1114\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     training_arg_passed_by_framework \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m call_context\u001b[38;5;241m.\u001b[39menter(\n\u001b[1;32m   1112\u001b[0m     layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, inputs\u001b[38;5;241m=\u001b[39minputs, build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39mtraining_value):\n\u001b[1;32m   1113\u001b[0m   \u001b[38;5;66;03m# Check input assumptions set after layer building, e.g. input shape.\u001b[39;00m\n\u001b[0;32m-> 1114\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_keras_tensor_symbolic_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1117\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA layer\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms `call` method should return a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1119\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensor or a list of Tensors, not None \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1120\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(layer: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py:848\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(keras_tensor\u001b[38;5;241m.\u001b[39mKerasTensor, output_signature)\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 848\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_output_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py:886\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_scope()):  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    881\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m    882\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;66;03m# Build layer if applicable (if the `build` method has been\u001b[39;00m\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# overridden).\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;66;03m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[39;00m\n\u001b[0;32m--> 886\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    887\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[1;32m    888\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py:2659\u001b[0m, in \u001b[0;36mLayer._maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_is_default\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   2655\u001b[0m   \u001b[38;5;66;03m# Any setup work performed only once should happen in an `init_scope`\u001b[39;00m\n\u001b[1;32m   2656\u001b[0m   \u001b[38;5;66;03m# to avoid creating symbolic Tensors that will later pollute any eager\u001b[39;00m\n\u001b[1;32m   2657\u001b[0m   \u001b[38;5;66;03m# operations.\u001b[39;00m\n\u001b[1;32m   2658\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf_utils\u001b[38;5;241m.\u001b[39mmaybe_init_scope(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 2659\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shapes\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint:disable=not-callable\u001b[39;00m\n\u001b[1;32m   2660\u001b[0m \u001b[38;5;66;03m# We must set also ensure that the layer is marked as built, and the build\u001b[39;00m\n\u001b[1;32m   2661\u001b[0m \u001b[38;5;66;03m# shape is stored since user defined build functions may not be calling\u001b[39;00m\n\u001b[1;32m   2662\u001b[0m \u001b[38;5;66;03m# `super.build()`\u001b[39;00m\n\u001b[1;32m   2663\u001b[0m Layer\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m, input_shapes)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/layers/convolutional.py:197\u001b[0m, in \u001b[0;36mConv.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    189\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    190\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe number of input channels must be evenly divisible by the number \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    191\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mof groups. Received groups=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, but the input has \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m channels \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    192\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(full input shape is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups, input_channel,\n\u001b[1;32m    193\u001b[0m                                          input_shape))\n\u001b[1;32m    194\u001b[0m kernel_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size \u001b[38;5;241m+\u001b[39m (input_channel \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    195\u001b[0m                                    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters)\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_weight\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkernel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_regularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias:\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\n\u001b[1;32m    207\u001b[0m       name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    208\u001b[0m       shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    212\u001b[0m       trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    213\u001b[0m       dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py:647\u001b[0m, in \u001b[0;36mLayer.add_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m     tf_logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    643\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`caching_device` does not work with mixed precision API. Ignoring \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    644\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser specified `caching_device`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    645\u001b[0m     caching_device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 647\u001b[0m variable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_variable_with_custom_getter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO(allenl): a `make_variable` equivalent should be added as a\u001b[39;49;00m\n\u001b[1;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# `Trackable` method.\u001b[39;49;00m\n\u001b[1;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgetter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgetter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Manage errors in Layer rather than Trackable.\u001b[39;49;00m\n\u001b[1;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_resource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections_arg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m regularizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    665\u001b[0m   \u001b[38;5;66;03m# TODO(fchollet): in the future, this should be handled at the\u001b[39;00m\n\u001b[1;32m    666\u001b[0m   \u001b[38;5;66;03m# level of variable creation, and weight regularization losses\u001b[39;00m\n\u001b[1;32m    667\u001b[0m   \u001b[38;5;66;03m# should be variable attributes.\u001b[39;00m\n\u001b[1;32m    668\u001b[0m   name_in_scope \u001b[38;5;241m=\u001b[39m variable\u001b[38;5;241m.\u001b[39mname[:variable\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py:813\u001b[0m, in \u001b[0;36mTrackable._add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    803\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (checkpoint_initializer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    804\u001b[0m       \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(initializer, CheckpointInitialValueCallable) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    805\u001b[0m            (initializer\u001b[38;5;241m.\u001b[39mrestore_uid \u001b[38;5;241m>\u001b[39m checkpoint_initializer\u001b[38;5;241m.\u001b[39mrestore_uid))):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;66;03m# then we'll catch that when we call _track_trackable. So this is\u001b[39;00m\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;66;03m# \"best effort\" to set the initializer with the highest restore UID.\u001b[39;00m\n\u001b[1;32m    812\u001b[0m     initializer \u001b[38;5;241m=\u001b[39m checkpoint_initializer\n\u001b[0;32m--> 813\u001b[0m new_variable \u001b[38;5;241m=\u001b[39m \u001b[43mgetter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_for_getter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;66;03m# If we set an initializer and the variable processed it, tracking will not\u001b[39;00m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# assign again. It will add this variable to our dependencies, and if there\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# is a non-trivial restoration queued, it will handle that. This also\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# handles slot variables.\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overwrite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_variable, Trackable):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer_utils.py:117\u001b[0m, in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    112\u001b[0m   use_resource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# In theory, in `use_resource` is True and `collections` is empty\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# (that is to say, in TF2), we can use tf.Variable.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# However, this breaks legacy (Estimator) checkpoints\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# because it changes variable names. Remove this when V1 is fully deprecated.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_resource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvariable_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:266\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    265\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m VariableV1:\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_v1_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m   \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m Variable:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_v2_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:212\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aggregation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m   aggregation \u001b[38;5;241m=\u001b[39m VariableAggregation\u001b[38;5;241m.\u001b[39mNONE\n\u001b[0;32m--> 212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprevious_getter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariable_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpected_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimport_scope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimport_scope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_resource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:205\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v1_call.<locals>.<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_variable_v1_call\u001b[39m(\u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m    189\u001b[0m                       initial_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    190\u001b[0m                       trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m                       aggregation\u001b[38;5;241m=\u001b[39mVariableAggregation\u001b[38;5;241m.\u001b[39mNONE,\n\u001b[1;32m    203\u001b[0m                       shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;124;03m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m   previous_getter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mdefault_variable_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m _, getter \u001b[38;5;129;01min\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\u001b[38;5;241m.\u001b[39m_variable_creator_stack:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    207\u001b[0m     previous_getter \u001b[38;5;241m=\u001b[39m _make_getter(getter, previous_getter)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/variable_scope.py:2612\u001b[0m, in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_resource:\n\u001b[1;32m   2611\u001b[0m   distribute_strategy \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistribute_strategy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 2612\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResourceVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[43m      \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2614\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2615\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2616\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2617\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2618\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2619\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2620\u001b[0m \u001b[43m      \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2621\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvariable_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2622\u001b[0m \u001b[43m      \u001b[49m\u001b[43mimport_scope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimport_scope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2623\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2624\u001b[0m \u001b[43m      \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2625\u001b[0m \u001b[43m      \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2626\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2627\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2628\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m variables\u001b[38;5;241m.\u001b[39mRefVariable(\n\u001b[1;32m   2629\u001b[0m       initial_value\u001b[38;5;241m=\u001b[39minitial_value,\n\u001b[1;32m   2630\u001b[0m       trainable\u001b[38;5;241m=\u001b[39mtrainable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2641\u001b[0m       aggregation\u001b[38;5;241m=\u001b[39maggregation,\n\u001b[1;32m   2642\u001b[0m       shape\u001b[38;5;241m=\u001b[39mshape)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:270\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_v2_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mVariableMetaclass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:1602\u001b[0m, in \u001b[0;36mResourceVariable.__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1600\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_from_proto(variable_def, import_scope\u001b[38;5;241m=\u001b[39mimport_scope)\n\u001b[1;32m   1601\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1602\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_from_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[43m      \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1605\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1606\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1608\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[43m      \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[43m      \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m      \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1612\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:1740\u001b[0m, in \u001b[0;36mResourceVariable._init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializer\u001b[39m\u001b[38;5;124m\"\u001b[39m), device_context_manager(\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1739\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m init_from_fn:\n\u001b[0;32m-> 1740\u001b[0m     initial_value \u001b[38;5;241m=\u001b[39m \u001b[43minitial_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1741\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(initial_value, trackable\u001b[38;5;241m.\u001b[39mCheckpointInitialValue):\n\u001b[1;32m   1742\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_initialize_trackable()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/initializers/initializers_v2.py:517\u001b[0m, in \u001b[0;36mVarianceScaling.__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    516\u001b[0m   limit \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m3.0\u001b[39m \u001b[38;5;241m*\u001b[39m scale)\n\u001b[0;32m--> 517\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_random_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_uniform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/initializers/initializers_v2.py:972\u001b[0m, in \u001b[0;36m_RandomGenerator.random_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    971\u001b[0m   op \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform\n\u001b[0;32m--> 972\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m    208\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m    209\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/random_ops.py:296\u001b[0m, in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    294\u001b[0m   maxval \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_uniform\u001b[39m\u001b[38;5;124m\"\u001b[39m, [shape, minval, maxval]) \u001b[38;5;28;01mas\u001b[39;00m name:\n\u001b[0;32m--> 296\u001b[0m   shape \u001b[38;5;241m=\u001b[39m \u001b[43mtensor_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m   \u001b[38;5;66;03m# In case of [0,1) floating results, minval and maxval is unused. We do an\u001b[39;00m\n\u001b[1;32m    298\u001b[0m   \u001b[38;5;66;03m# `is` comparison here since this is cheaper than isinstance or  __eq__.\u001b[39;00m\n\u001b[1;32m    299\u001b[0m   minval_is_zero \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(minval, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m minval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py:1080\u001b[0m, in \u001b[0;36mshape_tensor\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m   1074\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m     \u001b[38;5;66;03m# If there are Dimension objects in the shape, unwrap them. This can be a\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m     \u001b[38;5;66;03m# problem if v1 and v2 TensorShape objects get mixed up in partial\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# conversions, leading to shapes such as (1, 2, Dimension(5)), which are\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;66;03m# not convertible to Tensors because of mixed content.\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m     shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(tensor_shape\u001b[38;5;241m.\u001b[39mdimension_value, shape))\n\u001b[0;32m-> 1080\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py:163\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1566\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1561\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor did not convert to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1562\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe preferred dtype: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1563\u001b[0m                       (ret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype, preferred_dtype\u001b[38;5;241m.\u001b[39mbase_dtype))\n\u001b[1;32m   1565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1566\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1569\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:346\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    344\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    345\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m--> 346\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:271\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    176\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:283\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    282\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 283\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[1;32m    286\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:308\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    307\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 308\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:105\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    103\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m--> 105\u001b[0m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mEagerTensor(value, ctx\u001b[38;5;241m.\u001b[39mdevice_name, dtype)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/context.py:555\u001b[0m, in \u001b[0;36mContext.ensure_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m     pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_ContextOptionsSetTfrtDistributedRuntime(\n\u001b[1;32m    552\u001b[0m         opts, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_tfrt_distributed_runtime)\n\u001b[1;32m    553\u001b[0m   pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_ContextOptionsSetRunEagerOpAsFunction(\n\u001b[1;32m    554\u001b[0m       opts, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_eager_op_as_function)\n\u001b[0;32m--> 555\u001b[0m   context_handle \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_NewContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m   pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_DeleteContextOptions(opts)\n",
      "\u001b[0;31mInternalError\u001b[0m: CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory"
     ]
    }
   ],
   "source": [
    "feature_extractor = tf.keras.applications.vgg16.VGG16(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=IMG_SIZE,\n",
    "    pooling=\"avg\",\n",
    ")\n",
    "\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze all layers except last convolutional block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# freeze all layers except last five\n",
    "for layer in feature_extractor.layers[:-9]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for i, layer in enumerate(feature_extractor.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add top layer to fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = feature_extractor.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(units=512, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(units=256, activation=\"relu\")(x)\n",
    "x = Dense(units=3, activation=\"softmax\")(x)\n",
    "\n",
    "transfer_model = Model(inputs=feature_extractor.input, outputs=x)\n",
    "\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model and define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transfer_model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.Recall(class_id=0),\n",
    "        tf.keras.metrics.Recall(class_id=1),\n",
    "        tf.keras.metrics.Recall(class_id=2),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    f\"{projectdir}/vision/model_checkpoints/resample/vgg_top_fine_tuned_best_epoch_undersample.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode=\"min\",\n",
    "    save_freq=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    #model_checkpoint,\n",
    "    #tf.keras.callbacks.ReduceLROnPlateau(verbose=1),\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3, verbose=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "history = transfer_model.fit(\n",
    "    train_datagen, validation_data=val_datagen, epochs=20, callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load best checkpoint\n",
    "best_model = tf.keras.models.load_model(\n",
    "    f\"{projectdir}/vision/model_checkpoints/resample/vgg_top_fine_tuned_best_epoch_undersample.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.evaluate(val_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_logits = best_model.predict(val_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = np.argmax(y_preds_logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        y_true=val_datagen.classes,\n",
    "        y_pred=y_preds,\n",
    "        target_names=list(val_datagen.class_indices.keys()),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(train_datagen.classes).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cp ~/work/MED_Fall/vision/model_checkpoints/resample/vgg_top_fine_tuned_best_epoch_undersample.h5 ~/work/persistent/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Features Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = Sequential(best_model.layers[:-5])\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in feature_extractor.layers:\n",
    "    layer.trainable = False\n",
    "for layer in feature_extractor.layers:\n",
    "    print(layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_extractor.save(f\"{projectdir}/vision/models/vgg_feature_extractor.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = feature_extractor.predict(np.ones(shape=(1, 224, 224, 3)))\n",
    "print(pred_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "045da2998f02dde6c755b0fa2e74d8766d7d056d6163358ab445ad432d6df67f"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
