{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectdir = \"/home/jovyan/work/MED_Fall\"\n",
    "workdir = \"/home/jovyan/work\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/work/MED_Fall/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTHONPATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "\n",
    "from vision.pre_processing.extract_frames import FramesExtractor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from utils.utility_functions import listdir_nohidden_sorted as lsdir\n",
    "from utils.utility_functions import load_images, show_images\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup the dataframe for keras flow_from_dataframe pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_frames_path = (\n",
    "    \"/home/jovyan/work/MED_Fall/vision/vision_dataset/extracted_frames\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_old_path = (\n",
    "    \"/home/jovyan/work/MED_Fall/vision/vision_dataset/ground_truth_old\"\n",
    ")\n",
    "ground_truth_path = \"/home/jovyan/work/MED_Fall/vision/vision_dataset/ground_truth\"\n",
    "len(lsdir(ground_truth_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for file in lsdir(ground_truth_path):\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "dataset = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_old = []\n",
    "for file in lsdir(ground_truth_old_path):\n",
    "    df_old = pd.read_csv(file)\n",
    "    dfs_old.append(df_old)\n",
    "dataset_old = pd.concat(dfs_old, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0004.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182295</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4615.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182296</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4616.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182297</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4617.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182298</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4618.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182299</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4619.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1182300 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                micro_labels macro_labels            ar_labels  \\\n",
       "0                  lie_still   lying_down  actor_repositioning   \n",
       "1                  lie_still   lying_down  actor_repositioning   \n",
       "2                  lie_still   lying_down  actor_repositioning   \n",
       "3                  lie_still   lying_down  actor_repositioning   \n",
       "4                  lie_still   lying_down  actor_repositioning   \n",
       "...                      ...          ...                  ...   \n",
       "1182295  stand_up_from_floor          adl  actor_repositioning   \n",
       "1182296  stand_up_from_floor          adl  actor_repositioning   \n",
       "1182297  stand_up_from_floor          adl  actor_repositioning   \n",
       "1182298  stand_up_from_floor          adl  actor_repositioning   \n",
       "1182299  stand_up_from_floor          adl  actor_repositioning   \n",
       "\n",
       "                                   frame_name  \n",
       "0                  actor_1_bed_cam_1_0000.jpg  \n",
       "1                  actor_1_bed_cam_1_0001.jpg  \n",
       "2                  actor_1_bed_cam_1_0002.jpg  \n",
       "3                  actor_1_bed_cam_1_0003.jpg  \n",
       "4                  actor_1_bed_cam_1_0004.jpg  \n",
       "...                                       ...  \n",
       "1182295  actor_4_chair_full_ph_cam_7_4615.jpg  \n",
       "1182296  actor_4_chair_full_ph_cam_7_4616.jpg  \n",
       "1182297  actor_4_chair_full_ph_cam_7_4617.jpg  \n",
       "1182298  actor_4_chair_full_ph_cam_7_4618.jpg  \n",
       "1182299  actor_4_chair_full_ph_cam_7_4619.jpg  \n",
       "\n",
       "[1182300 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"frame_name\"] = (\n",
    "    dataset_old[\"frame_name\"] + \".jpg\"\n",
    ")  # add extension to file_names\n",
    "\n",
    "dataset = dataset.iloc[:, 1:]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualize some frames from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0206.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0207.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0208.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0209.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_1_0210.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182213</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4533.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182214</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4534.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182215</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4535.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182216</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4536.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182217</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4537.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>386106 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              micro_labels macro_labels ar_labels  \\\n",
       "206      sit_up_from_lying          adl    on_air   \n",
       "207      sit_up_from_lying          adl    on_air   \n",
       "208      sit_up_from_lying          adl    on_air   \n",
       "209      sit_up_from_lying          adl    on_air   \n",
       "210      sit_up_from_lying          adl    on_air   \n",
       "...                    ...          ...       ...   \n",
       "1182213     crouched_still      falling    on_air   \n",
       "1182214     crouched_still      falling    on_air   \n",
       "1182215     crouched_still      falling    on_air   \n",
       "1182216     crouched_still      falling    on_air   \n",
       "1182217     crouched_still      falling    on_air   \n",
       "\n",
       "                                   frame_name  \n",
       "206                actor_1_bed_cam_1_0206.jpg  \n",
       "207                actor_1_bed_cam_1_0207.jpg  \n",
       "208                actor_1_bed_cam_1_0208.jpg  \n",
       "209                actor_1_bed_cam_1_0209.jpg  \n",
       "210                actor_1_bed_cam_1_0210.jpg  \n",
       "...                                       ...  \n",
       "1182213  actor_4_chair_full_ph_cam_7_4533.jpg  \n",
       "1182214  actor_4_chair_full_ph_cam_7_4534.jpg  \n",
       "1182215  actor_4_chair_full_ph_cam_7_4535.jpg  \n",
       "1182216  actor_4_chair_full_ph_cam_7_4536.jpg  \n",
       "1182217  actor_4_chair_full_ph_cam_7_4537.jpg  \n",
       "\n",
       "[386106 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##removector actor repositioning frames\n",
    "on_air_ds = dataset.loc[dataset[\"ar_labels\"] == \"on_air\"]\n",
    "on_air_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>729793</th>\n",
       "      <td>stand_up_from_sit</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_2_walk_armour_obj_cam_1_2353.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485144</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_2_bed_armour_cam_5_3104.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431421</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_2_bed_cam_2_1701.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892584</th>\n",
       "      <td>stand_still</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_3_chair_full_ph_cam_6_0264.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10256</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_1_bed_cam_3_1616.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             micro_labels macro_labels ar_labels  \\\n",
       "729793  stand_up_from_sit          adl    on_air   \n",
       "485144  sit_up_from_lying          adl    on_air   \n",
       "431421  sit_up_from_lying          adl    on_air   \n",
       "892584        stand_still          adl    on_air   \n",
       "10256   sit_up_from_lying          adl    on_air   \n",
       "\n",
       "                                    frame_name  \n",
       "729793  actor_2_walk_armour_obj_cam_1_2353.jpg  \n",
       "485144       actor_2_bed_armour_cam_5_3104.jpg  \n",
       "431421              actor_2_bed_cam_2_1701.jpg  \n",
       "892584    actor_3_chair_full_ph_cam_6_0264.jpg  \n",
       "10256               actor_1_bed_cam_3_1616.jpg  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_samples = on_air_ds.groupby(\"macro_labels\").sample(n=10)\n",
    "rand_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729793         actor_2_walk_armour_obj_cam_1_2353.jpg -- adl\n",
       "485144              actor_2_bed_armour_cam_5_3104.jpg -- adl\n",
       "431421                     actor_2_bed_cam_2_1701.jpg -- adl\n",
       "892584           actor_3_chair_full_ph_cam_6_0264.jpg -- adl\n",
       "10256                      actor_1_bed_cam_3_1616.jpg -- adl\n",
       "239445           actor_1_walk2_full_ph_cam_4_3945.jpg -- adl\n",
       "993491      actor_3_walk_stick_full_ph_cam_4_3131.jpg -- adl\n",
       "212448           actor_1_walk2_full_ph_cam_1_0348.jpg -- adl\n",
       "62133              actor_1_bed_full_ph_cam_7_2373.jpg -- adl\n",
       "739531         actor_2_walk_armour_obj_cam_5_1051.jpg -- adl\n",
       "169496       actor_1_chair_full_ph_cam_4_2936.jpg -- falling\n",
       "21263                  actor_1_bed_cam_5_3983.jpg -- falling\n",
       "101319         actor_1_bed_rolling_cam_7_0279.jpg -- falling\n",
       "649316     actor_2_rolling_full_ph_cam_2_1136.jpg -- falling\n",
       "363683             actor_1_walk_ph_cam_6_4943.jpg -- falling\n",
       "285048                actor_1_walk_cam_4_1068.jpg -- falling\n",
       "903891             actor_3_rolling_cam_7_0291.jpg -- falling\n",
       "105865     actor_1_bed_rolling_full_ph_cam_3_0985.jpg -- ...\n",
       "44731          actor_1_bed_full_ph_cam_3_4651.jpg -- falling\n",
       "1149791              actor_4_chair_cam_7_2171.jpg -- falling\n",
       "265554     actor_1_walk2_full_ph_cam_7_6654.jpg -- lying_...\n",
       "764057     actor_2_walk_full_ph_cam_5_1217.jpg -- lying_down\n",
       "404320     actor_1_walk_shoe_full_ph_cam_6_3520.jpg -- ly...\n",
       "892987     actor_3_chair_full_ph_cam_6_0667.jpg -- lying_...\n",
       "747975     actor_2_walk_full_ph_cam_1_1215.jpg -- lying_down\n",
       "12509               actor_1_bed_cam_3_3869.jpg -- lying_down\n",
       "709406      actor_2_walk_armour_cam_2_2486.jpg -- lying_down\n",
       "827151              actor_3_bed_cam_2_1311.jpg -- lying_down\n",
       "851713      actor_3_bed_full_ph_cam_4_0133.jpg -- lying_down\n",
       "152797            actor_1_chair_cam_7_2797.jpg -- lying_down\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##concatenare alla macro label il nome del fotogramma\n",
    "titles = rand_samples[\"frame_name\"] + \" -- \" + rand_samples[\"macro_labels\"]\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[dataset[\"frame_name\"] == \"actor_2_bed_cam_3_3843.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = load_images(extracted_frames_path, rand_samples[\"frame_name\"])\n",
    "\n",
    "show_images(\n",
    "    images,\n",
    "    rows=5,\n",
    "    figsize=(30, 20),\n",
    "    titles=titles,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Subsample dataset choosing Actor 4 as fine tuning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only actor 4\n",
    "actor_4_dataset = dataset[dataset[\"frame_name\"].str.contains(\"actor_4\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_bed_cam_1_0000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_bed_cam_1_0001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_bed_cam_1_0002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_bed_cam_1_0003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_bed_cam_1_0004.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168415</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4615.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168416</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4616.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168417</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4617.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168418</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4618.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168419</th>\n",
       "      <td>stand_up_from_floor</td>\n",
       "      <td>adl</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4619.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168420 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               micro_labels macro_labels            ar_labels  \\\n",
       "0                 lie_still   lying_down  actor_repositioning   \n",
       "1                 lie_still   lying_down  actor_repositioning   \n",
       "2                 lie_still   lying_down  actor_repositioning   \n",
       "3                 lie_still   lying_down  actor_repositioning   \n",
       "4                 lie_still   lying_down  actor_repositioning   \n",
       "...                     ...          ...                  ...   \n",
       "168415  stand_up_from_floor          adl  actor_repositioning   \n",
       "168416  stand_up_from_floor          adl  actor_repositioning   \n",
       "168417  stand_up_from_floor          adl  actor_repositioning   \n",
       "168418  stand_up_from_floor          adl  actor_repositioning   \n",
       "168419  stand_up_from_floor          adl  actor_repositioning   \n",
       "\n",
       "                                  frame_name  \n",
       "0                 actor_4_bed_cam_1_0000.jpg  \n",
       "1                 actor_4_bed_cam_1_0001.jpg  \n",
       "2                 actor_4_bed_cam_1_0002.jpg  \n",
       "3                 actor_4_bed_cam_1_0003.jpg  \n",
       "4                 actor_4_bed_cam_1_0004.jpg  \n",
       "...                                      ...  \n",
       "168415  actor_4_chair_full_ph_cam_7_4615.jpg  \n",
       "168416  actor_4_chair_full_ph_cam_7_4616.jpg  \n",
       "168417  actor_4_chair_full_ph_cam_7_4617.jpg  \n",
       "168418  actor_4_chair_full_ph_cam_7_4618.jpg  \n",
       "168419  actor_4_chair_full_ph_cam_7_4619.jpg  \n",
       "\n",
       "[168420 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_4_dataset.reset_index(drop=True, inplace=True)\n",
    "actor_4_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_0126.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_0127.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_0128.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_0129.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_0130.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168333</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4533.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168334</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4534.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168335</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4535.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168336</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4536.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168337</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_7_4537.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39368 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             micro_labels macro_labels ar_labels  \\\n",
       "126     sit_up_from_lying          adl    on_air   \n",
       "127     sit_up_from_lying          adl    on_air   \n",
       "128     sit_up_from_lying          adl    on_air   \n",
       "129     sit_up_from_lying          adl    on_air   \n",
       "130     sit_up_from_lying          adl    on_air   \n",
       "...                   ...          ...       ...   \n",
       "168333     crouched_still      falling    on_air   \n",
       "168334     crouched_still      falling    on_air   \n",
       "168335     crouched_still      falling    on_air   \n",
       "168336     crouched_still      falling    on_air   \n",
       "168337     crouched_still      falling    on_air   \n",
       "\n",
       "                                  frame_name  \n",
       "126               actor_4_bed_cam_1_0126.jpg  \n",
       "127               actor_4_bed_cam_1_0127.jpg  \n",
       "128               actor_4_bed_cam_1_0128.jpg  \n",
       "129               actor_4_bed_cam_1_0129.jpg  \n",
       "130               actor_4_bed_cam_1_0130.jpg  \n",
       "...                                      ...  \n",
       "168333  actor_4_chair_full_ph_cam_7_4533.jpg  \n",
       "168334  actor_4_chair_full_ph_cam_7_4534.jpg  \n",
       "168335  actor_4_chair_full_ph_cam_7_4535.jpg  \n",
       "168336  actor_4_chair_full_ph_cam_7_4536.jpg  \n",
       "168337  actor_4_chair_full_ph_cam_7_4537.jpg  \n",
       "\n",
       "[39368 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_4_dataset = actor_4_dataset.loc[actor_4_dataset[\"ar_labels\"] == \"on_air\"]\n",
    "actor_4_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_images() missing 1 required positional argument: 'resize_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m some_actor_4_samples \u001b[38;5;241m=\u001b[39m actor_4_dataset\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mload_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextracted_frames_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msome_actor_4_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mframe_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m show_images(images, titles\u001b[38;5;241m=\u001b[39msome_actor_4_samples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: load_images() missing 1 required positional argument: 'resize_shape'"
     ]
    }
   ],
   "source": [
    "some_actor_4_samples = actor_4_dataset.groupby(\"macro_labels\").sample(n=5)\n",
    "images = load_images(extracted_frames_path, some_actor_4_samples[\"frame_name\"])\n",
    "\n",
    "show_images(images, titles=some_actor_4_samples[\"macro_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35431, 4) (3937, 4)\n"
     ]
    }
   ],
   "source": [
    "train_set = actor_4_dataset.sample(frac=0.9, random_state=2)\n",
    "val_set = actor_4_dataset.drop(train_set.index)\n",
    "\n",
    "print(train_set.shape, val_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adl           23140\n",
       "falling       11677\n",
       "lying_down      614\n",
       "Name: macro_labels, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[\"macro_labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stand_up_from_sit</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_cam_3_1280.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rolling_bed</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_3_6665.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rolling_bed</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_7_6653.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_7_0827.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_5_2467.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23135</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_7_0718.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23136</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_0594.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23137</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_4_3192.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23138</th>\n",
       "      <td>stand_up_from_sit</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_3_1521.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23139</th>\n",
       "      <td>stand_up_from_sit</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_6_0232.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23140 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            micro_labels macro_labels ar_labels  \\\n",
       "0      stand_up_from_sit          adl    on_air   \n",
       "1            rolling_bed          adl    on_air   \n",
       "2            rolling_bed          adl    on_air   \n",
       "3      sit_up_from_lying          adl    on_air   \n",
       "4      sit_up_from_lying          adl    on_air   \n",
       "...                  ...          ...       ...   \n",
       "23135  sit_up_from_lying          adl    on_air   \n",
       "23136  sit_up_from_lying          adl    on_air   \n",
       "23137  sit_up_from_lying          adl    on_air   \n",
       "23138  stand_up_from_sit          adl    on_air   \n",
       "23139  stand_up_from_sit          adl    on_air   \n",
       "\n",
       "                                 frame_name  \n",
       "0              actor_4_chair_cam_3_1280.jpg  \n",
       "1        actor_4_bed_full_ph_cam_3_6665.jpg  \n",
       "2        actor_4_bed_full_ph_cam_7_6653.jpg  \n",
       "3        actor_4_bed_full_ph_cam_7_0827.jpg  \n",
       "4        actor_4_bed_full_ph_cam_5_2467.jpg  \n",
       "...                                     ...  \n",
       "23135    actor_4_bed_full_ph_cam_7_0718.jpg  \n",
       "23136            actor_4_bed_cam_1_0594.jpg  \n",
       "23137    actor_4_bed_full_ph_cam_4_3192.jpg  \n",
       "23138  actor_4_chair_full_ph_cam_3_1521.jpg  \n",
       "23139            actor_4_bed_cam_6_0232.jpg  \n",
       "\n",
       "[23140 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adl_train = train_set.loc[train_set[\"macro_labels\"] == \"adl\"]\n",
    "adl_train.reset_index(drop=True, inplace=True)\n",
    "adl_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11677"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lying_down_n_samples = train_set[\"macro_labels\"].value_counts()[1]\n",
    "lying_down_n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15847</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_2_3172.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10831</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_1_1795.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21927</th>\n",
       "      <td>stand_up_from_sit</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_cam_4_1319.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>stand_up_from_sit</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_1_4425.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11744</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_5_0807.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9346</th>\n",
       "      <td>stand_up_from_sit</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_cam_7_1280.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>stand_up_from_sit</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_1225.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22070</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_5_2274.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_4_0724.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15293</th>\n",
       "      <td>stand_up_from_sit</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_knee_cam_1_1130.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11677 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            micro_labels macro_labels ar_labels  \\\n",
       "15847  sit_up_from_lying          adl    on_air   \n",
       "10831  sit_up_from_lying          adl    on_air   \n",
       "21927  stand_up_from_sit          adl    on_air   \n",
       "2059   stand_up_from_sit          adl    on_air   \n",
       "11744  sit_up_from_lying          adl    on_air   \n",
       "...                  ...          ...       ...   \n",
       "9346   stand_up_from_sit          adl    on_air   \n",
       "1622   stand_up_from_sit          adl    on_air   \n",
       "22070  sit_up_from_lying          adl    on_air   \n",
       "2725   sit_up_from_lying          adl    on_air   \n",
       "15293  stand_up_from_sit          adl    on_air   \n",
       "\n",
       "                                    frame_name  \n",
       "15847       actor_4_bed_full_ph_cam_2_3172.jpg  \n",
       "10831       actor_4_bed_full_ph_cam_1_1795.jpg  \n",
       "21927             actor_4_chair_cam_4_1319.jpg  \n",
       "2059      actor_4_chair_full_ph_cam_1_4425.jpg  \n",
       "11744       actor_4_bed_full_ph_cam_5_0807.jpg  \n",
       "...                                        ...  \n",
       "9346              actor_4_chair_cam_7_1280.jpg  \n",
       "1622                actor_4_bed_cam_1_1225.jpg  \n",
       "22070               actor_4_bed_cam_5_2274.jpg  \n",
       "2725        actor_4_bed_full_ph_cam_4_0724.jpg  \n",
       "15293  actor_4_bed_full_ph_knee_cam_1_1130.jpg  \n",
       "\n",
       "[11677 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adl_train_under = adl_train.sample(n=lying_down_n_samples, random_state=2)\n",
    "adl_train_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158570</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_5_4010.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72172</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_5_5812.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156754</th>\n",
       "      <td>fall_lateral</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_5_2194.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111137</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_knee_cam_7_1217.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18422</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_7_1862.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146953</th>\n",
       "      <td>fall_lateral</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_3_1633.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17235</th>\n",
       "      <td>fall_frontal</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_7_0675.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142899</th>\n",
       "      <td>fall_lateral</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_2_2199.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17262</th>\n",
       "      <td>fall_frontal</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_7_0702.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146931</th>\n",
       "      <td>fall_lateral</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_3_1611.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12291 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 micro_labels macro_labels ar_labels  \\\n",
       "158570         crouched_still      falling    on_air   \n",
       "72172   lie_down_on_the_floor   lying_down    on_air   \n",
       "156754           fall_lateral      falling    on_air   \n",
       "111137         crouched_still      falling    on_air   \n",
       "18422   lie_down_on_the_floor   lying_down    on_air   \n",
       "...                       ...          ...       ...   \n",
       "146953           fall_lateral      falling    on_air   \n",
       "17235            fall_frontal      falling    on_air   \n",
       "142899           fall_lateral      falling    on_air   \n",
       "17262            fall_frontal      falling    on_air   \n",
       "146931           fall_lateral      falling    on_air   \n",
       "\n",
       "                                     frame_name  \n",
       "158570     actor_4_chair_full_ph_cam_5_4010.jpg  \n",
       "72172        actor_4_bed_full_ph_cam_5_5812.jpg  \n",
       "156754     actor_4_chair_full_ph_cam_5_2194.jpg  \n",
       "111137  actor_4_bed_full_ph_knee_cam_7_1217.jpg  \n",
       "18422                actor_4_bed_cam_7_1862.jpg  \n",
       "...                                         ...  \n",
       "146953     actor_4_chair_full_ph_cam_3_1633.jpg  \n",
       "17235                actor_4_bed_cam_7_0675.jpg  \n",
       "142899     actor_4_chair_full_ph_cam_2_2199.jpg  \n",
       "17262                actor_4_bed_cam_7_0702.jpg  \n",
       "146931     actor_4_chair_full_ph_cam_3_1611.jpg  \n",
       "\n",
       "[12291 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_copy = train_set.copy()\n",
    "train_set_copy = train_set_copy[train_set_copy[\"macro_labels\"] != \"adl\"]\n",
    "train_set_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "falling       11677\n",
       "lying_down      614\n",
       "Name: macro_labels, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_copy[\"macro_labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158570</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_5_4010.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72172</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_5_5812.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156754</th>\n",
       "      <td>fall_lateral</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_full_ph_cam_5_2194.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111137</th>\n",
       "      <td>crouched_still</td>\n",
       "      <td>falling</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_knee_cam_7_1217.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18422</th>\n",
       "      <td>lie_down_on_the_floor</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_7_1862.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9346</th>\n",
       "      <td>stand_up_from_sit</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_chair_cam_7_1280.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>stand_up_from_sit</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_1_1225.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22070</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_cam_5_2274.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>sit_up_from_lying</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_cam_4_0724.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15293</th>\n",
       "      <td>stand_up_from_sit</td>\n",
       "      <td>adl</td>\n",
       "      <td>on_air</td>\n",
       "      <td>actor_4_bed_full_ph_knee_cam_1_1130.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23968 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 micro_labels macro_labels ar_labels  \\\n",
       "158570         crouched_still      falling    on_air   \n",
       "72172   lie_down_on_the_floor   lying_down    on_air   \n",
       "156754           fall_lateral      falling    on_air   \n",
       "111137         crouched_still      falling    on_air   \n",
       "18422   lie_down_on_the_floor   lying_down    on_air   \n",
       "...                       ...          ...       ...   \n",
       "9346        stand_up_from_sit          adl    on_air   \n",
       "1622        stand_up_from_sit          adl    on_air   \n",
       "22070       sit_up_from_lying          adl    on_air   \n",
       "2725        sit_up_from_lying          adl    on_air   \n",
       "15293       stand_up_from_sit          adl    on_air   \n",
       "\n",
       "                                     frame_name  \n",
       "158570     actor_4_chair_full_ph_cam_5_4010.jpg  \n",
       "72172        actor_4_bed_full_ph_cam_5_5812.jpg  \n",
       "156754     actor_4_chair_full_ph_cam_5_2194.jpg  \n",
       "111137  actor_4_bed_full_ph_knee_cam_7_1217.jpg  \n",
       "18422                actor_4_bed_cam_7_1862.jpg  \n",
       "...                                         ...  \n",
       "9346               actor_4_chair_cam_7_1280.jpg  \n",
       "1622                 actor_4_bed_cam_1_1225.jpg  \n",
       "22070                actor_4_bed_cam_5_2274.jpg  \n",
       "2725         actor_4_bed_full_ph_cam_4_0724.jpg  \n",
       "15293   actor_4_bed_full_ph_knee_cam_1_1130.jpg  \n",
       "\n",
       "[23968 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_copy = pd.concat([train_set_copy, adl_train_under], axis=0)\n",
    "train_set_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "falling       11677\n",
       "adl           11677\n",
       "lying_down      614\n",
       "Name: macro_labels, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_copy[\"macro_labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_images() missing 1 required positional argument: 'resize_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m some_samples \u001b[38;5;241m=\u001b[39m train_set_copy\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mload_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextracted_frames_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msome_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mframe_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m show_images(images, titles\u001b[38;5;241m=\u001b[39msome_samples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: load_images() missing 1 required positional argument: 'resize_shape'"
     ]
    }
   ],
   "source": [
    "some_samples = train_set_copy.groupby(\"macro_labels\").sample(n=5)\n",
    "images = load_images(extracted_frames_path, some_samples[\"frame_name\"])\n",
    "\n",
    "show_images(images, titles=some_samples[\"macro_labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fine tune VGG16 on Actor 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Training and Validation Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23968 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "\n",
    "train_datagen = train_generator.flow_from_dataframe(\n",
    "    train_set_copy,\n",
    "    directory=extracted_frames_path,\n",
    "    x_col=\"frame_name\",\n",
    "    y_col=\"macro_labels\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    classes=[\"adl\", \"lying_down\", \"falling\"],\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    seed=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3937 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "val_datagen = val_generator.flow_from_dataframe(\n",
    "    val_set,\n",
    "    directory=extracted_frames_path,\n",
    "    x_col=\"frame_name\",\n",
    "    y_col=\"macro_labels\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    classes=[\"adl\", \"lying_down\", \"falling\"],\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    seed=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    11677\n",
      "0    11677\n",
      "2      614\n",
      "dtype: int64\n",
      "{'adl': 0, 'falling': 1, 'lying_down': 2}\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(train_datagen.classes).value_counts())\n",
    "print(train_datagen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2564\n",
      "1    1315\n",
      "2      58\n",
      "dtype: int64\n",
      "{'adl': 0, 'falling': 1, 'lying_down': 2}\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(val_datagen.classes).value_counts())\n",
    "print(val_datagen.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download pre-trained VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 13:36:36.882110: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-22 13:36:37.304866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21353 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = tf.keras.applications.vgg16.VGG16(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=IMG_SIZE,\n",
    "    pooling=\"avg\",\n",
    ")\n",
    "\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze all layers except last convolutional block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv2 False\n",
      "3 block1_pool False\n",
      "4 block2_conv1 False\n",
      "5 block2_conv2 False\n",
      "6 block2_pool False\n",
      "7 block3_conv1 False\n",
      "8 block3_conv2 False\n",
      "9 block3_conv3 False\n",
      "10 block3_pool False\n",
      "11 block4_conv1 True\n",
      "12 block4_conv2 True\n",
      "13 block4_conv3 True\n",
      "14 block4_pool True\n",
      "15 block5_conv1 True\n",
      "16 block5_conv2 True\n",
      "17 block5_conv3 True\n",
      "18 block5_pool True\n",
      "19 global_average_pooling2d True\n"
     ]
    }
   ],
   "source": [
    "# freeze all layers except last five\n",
    "for layer in feature_extractor.layers[:-9]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for i, layer in enumerate(feature_extractor.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add top layer to fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 15,109,443\n",
      "Trainable params: 13,373,955\n",
      "Non-trainable params: 1,735,488\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = feature_extractor.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(units=512, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(units=256, activation=\"relu\")(x)\n",
    "x = Dense(units=3, activation=\"softmax\")(x)\n",
    "\n",
    "transfer_model = Model(inputs=feature_extractor.input, outputs=x)\n",
    "\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model and define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transfer_model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.Recall(class_id=0),\n",
    "        tf.keras.metrics.Recall(class_id=1),\n",
    "        tf.keras.metrics.Recall(class_id=2),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    f\"{projectdir}/vision/model_checkpoints/resample/vgg_top_fine_tuned_best_epoch_undersample.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode=\"min\",\n",
    "    save_freq=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    # model_checkpoint,\n",
    "    # tf.keras.callbacks.ReduceLROnPlateau(verbose=1),\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3, verbose=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 13:36:46.723833: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 13:36:48.489279: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n",
      "2022-08-22 13:36:52.191892: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument:  logits and labels must have the same first dimension, got logits shape [64,3] and labels shape [192]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at tmp/ipykernel_358705/607337168.py:1) ]]\n\t [[assert_less_equal/Assert/AssertGuard/pivot_f/_13/_43]]\n  (1) Invalid argument:  logits and labels must have the same first dimension, got logits shape [64,3] and labels shape [192]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at tmp/ipykernel_358705/607337168.py:1) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_2304]\n\nFunction call stack:\ntrain_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtransfer_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_datagen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_datagen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:950\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    947\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;66;03m# stateless function.\u001b[39;00m\n\u001b[0;32m--> 950\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    952\u001b[0m   _, _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    953\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    954\u001b[0m           \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   3037\u001b[0m   (graph_function,\n\u001b[1;32m   3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1962\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1965\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m     args,\n\u001b[1;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1968\u001b[0m     executing_eagerly)\n\u001b[1;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  logits and labels must have the same first dimension, got logits shape [64,3] and labels shape [192]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at tmp/ipykernel_358705/607337168.py:1) ]]\n\t [[assert_less_equal/Assert/AssertGuard/pivot_f/_13/_43]]\n  (1) Invalid argument:  logits and labels must have the same first dimension, got logits shape [64,3] and labels shape [192]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at tmp/ipykernel_358705/607337168.py:1) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_2304]\n\nFunction call stack:\ntrain_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "history = transfer_model.fit(\n",
    "    train_datagen, validation_data=val_datagen, epochs=20, callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load best checkpoint\n",
    "best_model = tf.keras.models.load_model(\n",
    "    f\"{projectdir}/vision/model_checkpoints/resample/vgg_top_fine_tuned_best_epoch_undersample.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.evaluate(val_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_logits = best_model.predict(val_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = np.argmax(y_preds_logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        y_true=val_datagen.classes,\n",
    "        y_pred=y_preds,\n",
    "        target_names=list(val_datagen.class_indices.keys()),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(train_datagen.classes).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cp ~/work/MED_Fall/vision/model_checkpoints/resample/vgg_top_fine_tuned_best_epoch_undersample.h5 ~/work/persistent/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Features Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = Sequential(best_model.layers[:-5])\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in feature_extractor.layers:\n",
    "    layer.trainable = False\n",
    "for layer in feature_extractor.layers:\n",
    "    print(layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_extractor.save(f\"{projectdir}/vision/models/vgg_feature_extractor.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = feature_extractor.predict(np.ones(shape=(1, 224, 224, 3)))\n",
    "print(pred_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "045da2998f02dde6c755b0fa2e74d8766d7d056d6163358ab445ad432d6df67f"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
